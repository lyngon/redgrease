{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedGrease Demo at RedisConf 2021\n",
    "\n",
    "Quick demonstration of how to create and run Redis Gears functions, using RedGrease.\n",
    "\n",
    "## [Demos](#Demos):\n",
    "1. [The Basics](#1.-The-Basics)\n",
    "2. [Simple Analytics Query](#2.-Simple-Analytics-Query)\n",
    "3. [Transaction Stream Processing](#3.-Transaction-Stream-Processing)\n",
    "4. [Custom Command](#4.-Custom-Command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations\n",
    "Before running the demos, make sure that the prerequisites are met and that the preparation steps have successfully been executed. \n",
    "Some preparation steps, particularly the downloads, may take quite some time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n",
    "- Python3.7\n",
    "- Pip\n",
    "- Docker\n",
    "- Jupyter\n",
    "\n",
    "Run the cell below tho validate your prerequisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements all look good!\n"
     ]
    }
   ],
   "source": [
    "# Run cell to test your environment requirements\n",
    "\n",
    "import sys\n",
    "import re\n",
    "pyver = !{sys.executable} --version  # type: ignore\n",
    "pipver = !{sys.executable} -m pip --version  # type: ignore\n",
    "dockver = !docker --version  # type: ignore\n",
    "\n",
    "if not re.match(\"Python 3.7\", pyver[0]):\n",
    "    raise SystemExit(f\"This demo only supports Python 3.7. You are running {pyver[0]}.\")\n",
    "\n",
    "if not re.match(\".*\\(python 3.7\\)\", pipver[0]):\n",
    "    raise SystemExit(\"Please install Pip for yout Python 3.7 environment.\")\n",
    "\n",
    "if not re.match(\"Docker version\", dockver[0]):\n",
    "    raise SystemExit(\"Please install Docker\")\n",
    "\n",
    "print(\"Requirements all look good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python Requirements\n",
    "\n",
    "Install the Python packages required for the demo:\n",
    "\n",
    "- `redgrease[client]` - The RedGrease client library for Redis Gears. This is what is being demonstrated.\n",
    "\n",
    "- `ipywidgets` - Jupyter notebook exetension, for displaying widgets, e.g. buttons, in this notebook.\n",
    "- `requests` - For downloading content.\n",
    "\n",
    "Run the cell below to install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture reqs_install_output\n",
    "!{sys.executable} -m pip install redgrease[client] ipywidgets requests\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Datasets\n",
    "Some of the demos requiere a portion of the [COCO Dataset](https://cocodataset.org) to be uploaded into the Redis Gears Cluster.\n",
    "The COCO Dataset (Common Objects in Context) is a fairly large set of (~247,000) images and corresponding annotations of what tey are depicting.\n",
    "\n",
    "### Example:\n",
    "<img src=\"coco_example.jpg\" > [COCO Example](coco_example.jpg)\n",
    "\n",
    "```\n",
    "a man riding a snowboard down a ski slope.\n",
    "a snowboarder sailing down a snowy hillside on a mountain.\n",
    "a man is snowboarding past blue markers on a mountain.\n",
    "a man on a snowboard in the snow.\n",
    "a man snow boarding in the snow on a slope. \n",
    "```\n",
    "\n",
    "\n",
    "For the demo we will only pre-download the annotations (json), not the images (jpeg), but it is still between 250 - 500 MB of data, depending on which portions you choose.\n",
    "\n",
    "There are two annotation packages to choose from. \n",
    "- **COCO Train/Cal 2014** - Annotations for 124,000 images (241 MB)\n",
    "- **COCO Train/Val 2017** - Annotations for 123,000 images (241 MB)\n",
    "\n",
    "Either or both may be used. \n",
    "Run the cell below and select using the buttons which dataset(s) to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc72c03408f4dae83568ad084347e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='/home/anders/Downloads/COCO', description='Directory to download annotations to.', layout=Layout(w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cd12f81da74033b088c53bdd475f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Congrats! COCO 2014 annotataions is downloaded!', disabled=True, layout=Layout(width='30%'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486beea3fd6f46508cd4f46962b1c980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Congrats! COCO 2017 annotataions is downloaded!', disabled=True, layout=Layout(width='30%'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602937f68e124bf5b801ecbcdcceb8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This code is just for preparation of the demo.\n",
    "# It is NOT part of the demo itself\n",
    "#\n",
    "# Download COCO Annotations \n",
    "# Run the cell, then:\n",
    "# - Validate or modify the Download directory\n",
    "# - Click the button, or buttons for the annotations to download\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import requests\n",
    "\n",
    "coco_annotations_url = \"http://images.cocodataset.org/annotations\"\n",
    "annotations_file_pattern = \"annotations_trainval{}.zip\"\n",
    "\n",
    "layout = widgets.Layout(width=\"30%\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def get_download_path():\n",
    "    download_dir = \".\"\n",
    "    if os.name == 'nt':\n",
    "        import winreg\n",
    "        sub_key = r'SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders'\n",
    "        downloads_guid = '{374DE290-123F-4565-9164-39C4925E467B}'\n",
    "        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, sub_key) as key:\n",
    "            download_dir = winreg.QueryValueEx(key, downloads_guid)[0]\n",
    "    else:\n",
    "        download_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "\n",
    "    return os.path.join(download_dir, \"COCO\")\n",
    "\n",
    "download_location = widgets.Text(\n",
    "    value=get_download_path(),\n",
    "    placeholder=\"Download directory\",\n",
    "    description=\"Directory to download annotations to.\",\n",
    "    layout=layout,\n",
    ")\n",
    "display(download_location)\n",
    "\n",
    "def dl_state(button, downloading=None):\n",
    "    year = button.value\n",
    "    annotations_file_name = annotations_file_pattern.format(year)\n",
    "    destination = os.path.join(download_location.value, annotations_file_name)\n",
    "    is_downloaded = os.path.isfile(destination)\n",
    "    button.disabled = is_downloaded or downloading is not None\n",
    "    if downloading:\n",
    "        button.description=f\"Downloading COCO {year} annotations (241 MB): {downloading}%. Please wait!\"\n",
    "    elif is_downloaded:\n",
    "        button.description=f\"Congrats! COCO {year} annotataions is downloaded!\"\n",
    "    else:\n",
    "        button.description=f\"Download COCO {year} annotations (241 MB)\"\n",
    "    return is_downloaded, annotations_file_name, destination\n",
    "\n",
    "\n",
    "def download_button_pressed(btn):\n",
    "    downloaded, file_name, destination = dl_state(btn)\n",
    "    if downloaded:\n",
    "        return\n",
    "    if not os.path.isdir(download_location.value):\n",
    "        os.mkdir(download_location.value)\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{coco_annotations_url}/{file_name}\",\n",
    "            stream=True\n",
    "        )\n",
    "        total_length = response.headers.get('content-length')\n",
    "        with open(destination, \"wb\") as f:\n",
    "            if total_length is None: # no content length header\n",
    "                dl_state(btn, \"???\")\n",
    "                f.write(response.content)\n",
    "                return\n",
    "            total_length = int(total_length)\n",
    "            dl = 0\n",
    "            for data in response.iter_content(chunk_size=4096):\n",
    "                dl += len(data)\n",
    "                f.write(data)\n",
    "                dl_state(btn, int(100*(dl/total_length)))\n",
    "\n",
    "    except Exception:\n",
    "        try:\n",
    "            os.remove(destination)\n",
    "        except Exception:\n",
    "            pass\n",
    "    finally:\n",
    "        dl_state(btn)\n",
    "\n",
    "for year in [\"2014\", \"2017\"]:\n",
    "    download_button = widgets.Button(\n",
    "        tooltip='Start download of selected datasets into the selected download directory.',\n",
    "        layout=layout\n",
    "    )\n",
    "    download_button.value = year\n",
    "    dl_state(download_button)\n",
    "    download_button.on_click(download_button_pressed)\n",
    "    display(download_button)\n",
    "\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download and run Redis Gears Cluster Docker image\n",
    "Run the cell below to download a Redis Gears Cluster Docker image (~605 MB), if not already present, and run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.6: Pulling from redislabs/redisgears\n",
      "Digest: sha256:ab126c449864cc9bc1b1facae26069c51d5f56760fb15b7a01371317fc69c17f\n",
      "Status: Image is up to date for redislabs/redisgears:1.0.6\n",
      "docker.io/redislabs/redisgears:1.0.6\n",
      "1.0.6: Pulling from redislabs/rgcluster\n",
      "Digest: sha256:563b2bf890085dc0b451de536fb7bacf8bfb98b6d1a162fda92f3b4742c4fd23\n",
      "Status: Image is up to date for redislabs/rgcluster:1.0.6\n",
      "docker.io/redislabs/rgcluster:1.0.6\n",
      "Redis Gears containers are running!\n"
     ]
    }
   ],
   "source": [
    "redis_gears_cluster_image = \"redislabs/rgcluster:1.0.6\"\n",
    "redis_gears_cluster_container_name = \"demo_gears_cluster\"\n",
    "\n",
    "redis_gears_single_image = \"redislabs/redisgears:1.0.6\"\n",
    "redis_gears_single_container_name = \"demo_gears_single\"\n",
    "\n",
    "# Get the correct Redis Gears Images\n",
    "!docker pull {redis_gears_single_image}\n",
    "!docker pull {redis_gears_cluster_image}\n",
    "\n",
    "# Check if the single container is already running.\n",
    "container_info = !docker container inspect {redis_gears_single_container_name}\n",
    "if container_info[0] == \"[]\":\n",
    "    print(\"Starting Redis Gears single instance\")\n",
    "    !docker run --name {redis_gears_single_container_name} --rm -d -p 6379:6379 {redis_gears_single_image}\n",
    "\n",
    "\n",
    "# Check if the cluster container is already running.\n",
    "container_info = !docker container inspect {redis_gears_cluster_container_name}\n",
    "if container_info[0] == \"[]\":\n",
    "    print(\"Starting Redis Gears cluster instance\")\n",
    "    !docker run --name {redis_gears_cluster_container_name} --rm -d -p 30001:30001 -p 30002:30002 -p 30003:30003 {redis_gears_cluster_image}\n",
    "\n",
    "print(\"Redis Gears containers are running!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Annotation Data into Redis cluster\n",
    "By running the cell below, the COCO annotations downloaded above will be loaded into the Redis Cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af191d268d644ca8b9f45e4bf89e28ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='30%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import redgrease\n",
    "import zipfile\n",
    "\n",
    "annotation_archive_files = os.path.join(download_location.value, \"annotations_trainval*.zip\")\n",
    "annotation_archives = glob.glob(annotation_archive_files)\n",
    "\n",
    "if not annotation_archives:\n",
    "    print(\"no archives\")\n",
    "    raise SystemExit(\"Please download either or both COCO annotations as per instructions above.\")\n",
    "\n",
    "r = redgrease.RedisGears(host=\"localhost\", port=30001)\n",
    "\n",
    "annotation_json_pattern = re.compile(\"annotations/(\\w+)_(\\w+).json\")\n",
    "\n",
    "annotation_types = [\"instances\"] #  , \"person_keypoints\", \"captions\"]\n",
    "datasets = [\"val2014\"]  # , \"train2014\", \"val2017\", \"train2017\"]\n",
    "\n",
    "output = widgets.Output()\n",
    "progress = widgets.Text(\"\", layout=layout)\n",
    "\n",
    "def load_annotation_info(info, dataset_name, annotation_type):\n",
    "    annotation_info_key = f\"/dataset/COCO/annotations/{annotation_type}/{dataset_name}/info\"\n",
    "    r.hset(annotation_info_key, mapping=info)\n",
    "    return annotation_info_key\n",
    "\n",
    "def load_license_info(license):\n",
    "    license_key = f\"/license/{license['id']}\"\n",
    "    if not r.exists(license_key):\n",
    "        r.hset(license_key, mapping=license)\n",
    "    return license_key\n",
    "\n",
    "def load_image_info(image_info):\n",
    "    img_info_key = f\"/dataset/COCO/image/{image_info['id']}/info\"\n",
    "    if not r.exists(img_info_key):\n",
    "        r.hset(img_info_key, mapping=image_info)\n",
    "    return img_info_key\n",
    "\n",
    "def load_keypoint_names(base_key, keypoints):\n",
    "    keypoints_key = f\"{base_key}/keypoints\"\n",
    "    r.lpush(keypoints_key, *keypoints)\n",
    "    return keypoints_key\n",
    "\n",
    "def load_list_of_str(base_key, sequence):\n",
    "    list_key = f\"{base_key}/skeleton\"\n",
    "    r.lpush(list_key, *map(str, sequence))\n",
    "    return list_key\n",
    "\n",
    "def load_category(category):\n",
    "    category_key = f\"/dataset/COCO/annotations/category/{category['id']}\"\n",
    "\n",
    "    if \"keypoints\" in category:\n",
    "        category[\"keypoints\"] = load_keypoint_names(category_key, category[\"keypoints\"])\n",
    "    if \"skeleton\" in category:\n",
    "        category[\"skeleton\"] = load_list_of_str(category_key, category[\"skeleton\"])\n",
    "\n",
    "    r.hset(category_key, mapping=category)\n",
    "    return category_key\n",
    "\n",
    "def load_segmentation(annotation_key, segmentation):\n",
    "    segmentation_key = f\"{annotation_key}/segmentation\"\n",
    "    if not r.exists(segmentation_key):\n",
    "        for i, segment in enumerate(segmentation):\n",
    "            segment_key = f\"{segmentation_key}/{i}\"\n",
    "            r.lpush(segment_key, *segment)\n",
    "            r.rpush(segmentation_key, segment_key)\n",
    "    return segmentation_key\n",
    "\n",
    "def load_annotation(annotation, dataset_name, annotation_type):\n",
    "    annotation_key = f\"/dataset/COCO/annotations/{annotation_type}/{dataset_name}/annotation/{annotation['id']}\"\n",
    "    \n",
    "    if not r.exists(annotation_key):\n",
    "        if \"segmentation\" in annotation:\n",
    "            # Replace the 'segmentation' list-of-lists, with a key with a list of keys, that in turn point to the inner lists :)\n",
    "            annotation[\"segmentation\"] = load_segmentation(annotation_key, annotation[\"segmentation\"])\n",
    "        \n",
    "        if \"bbox\" in annotation:\n",
    "            # Replace the 'bbox' with a string reepresentaton.load_segmentation\n",
    "            annotation[\"bbox\"] = str(annotation[\"bbox\"])\n",
    "\n",
    "        if \"keypoints\" in annotation:\n",
    "            annotation[\"keypoints\"] = load_list_of_str(annotation_key, annotation[\"keypoints\"])\n",
    "\n",
    "        r.hset(annotation_key, mapping=annotation)\n",
    "    return annotation_key\n",
    "\n",
    "def load_annotation_jsons_from_zip(zip_file):\n",
    "    with zipfile.ZipFile(zip_file) as archive:\n",
    "        for file_name in archive.namelist():\n",
    "            is_annotation_file = annotation_json_pattern.match(file_name)\n",
    "            if not is_annotation_file:\n",
    "                continue\n",
    "            \n",
    "            annotation_type = is_annotation_file.group(1)\n",
    "            dataset_name = is_annotation_file.group(2)\n",
    "\n",
    "            if not annotation_type in annotation_types:\n",
    "                continue\n",
    "            \n",
    "            if not dataset_name in datasets:\n",
    "                continue\n",
    "\n",
    "            with archive.open(file_name) as json_file:\n",
    "                contents = json.load(json_file)\n",
    "\n",
    "            # info\n",
    "            if \"info\" in contents:\n",
    "                progress.value = f\"Loading info for {dataset_name} {annotation_type}\"\n",
    "                load_annotation_info(contents[\"info\"], dataset_name, annotation_type)\n",
    "\n",
    "            # licenses\n",
    "            if \"licenses\" in contents:\n",
    "                progress.value = f\"Loading licenses for {dataset_name} {annotation_type}\"\n",
    "                for lic in contents[\"licenses\"]:\n",
    "                    load_license_info(lic)\n",
    "            \n",
    "            # images\n",
    "            if \"images\" in contents:\n",
    "                progress.value = f\"Loading images for {dataset_name} {annotation_type}\"\n",
    "                for image_info in contents[\"images\"]:\n",
    "                    load_image_info(image_info)\n",
    "\n",
    "            # annotations\n",
    "            if \"annotations\" in contents:\n",
    "                progress.value = f\"Loading annotations for {dataset_name} {annotation_type}\"\n",
    "                for annotation in contents[\"annotations\"]:\n",
    "                    load_annotation(annotation, dataset_name, annotation_type)\n",
    "\n",
    "            # categories (for \"instances\" and \"person_keypoints\")\n",
    "            if \"categories\" in contents:\n",
    "                progress.value = f\"Loading categories for {dataset_name} {annotation_type}\"\n",
    "                for category in contents[\"categories\"]:\n",
    "                    load_category(category)\n",
    "\n",
    "            \n",
    "display(progress)\n",
    "for archive in annotation_archives:\n",
    "    progress.value = f\"Unzipping {archive}\"\n",
    "    load_annotation_jsons_from_zip(archive)\n",
    "progress.value = \"Done!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos\n",
    "This is the actual Demo section. Everything above is just preparations.\n",
    "\n",
    "1. [The Basics](#1.-The-Basics)\n",
    "2. [Simple Analytics Query](#2.-Simple-Analytics-Query)\n",
    "3. [Transaction Stream Processing](#3.-Transaction-Stream-Processing)\n",
    "4. [Custom Command](#4.-Custom-Command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demm-basics\"></a>\n",
    "## 1. The Basics\n",
    "Showcasing some of the basic features and commands of the redgrease package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b\"{'event': None, 'key': 'Foo', 'type': 'string', 'value': '21'}\", b\"{'event': None, 'key': 'Bar', 'type': 'hash', 'value': {'meaning': '42', 'spam': 'eggs'}}\", b\"{'event': None, 'key': 'tlogs::0', 'type': 'unknown', 'value': None}\"]\n"
     ]
    }
   ],
   "source": [
    "import redgrease\n",
    "import redgrease.utils\n",
    "\n",
    "# Create connectoin / client for Redis Cluster \n",
    "cluster = redgrease.RedisCluster(host=\"localhost\", port=30001)  # RedisGears(host=\"localhost\", port=30001)\n",
    "\n",
    "# Create connection / client for single instance Redis\n",
    "single = redgrease.Redis()  # RedisGears()\n",
    "\n",
    "# The usual Redis commands work as expected\n",
    "a = single.flushall()\n",
    "b = single.set(\"Foo\", 21)\n",
    "c = single.hset(\"Bar\", mapping={\"spam\":\"eggs\", \"meaning\":8})\n",
    "d = single.hincrby(\"Bar\", \"meaning\", 34)\n",
    "e = single.xadd(\"tlogs::0\", {\"msg\":\"START\", \"from\":0, \"to\":0, \"amount\":0})\n",
    "\n",
    "# Gears commands can be accessed through the 'gears' attribute\n",
    "single.gears.pystats()\n",
    "\n",
    "basic_gear = single.gears.pyexecute(\"GB().run()\")\n",
    "\n",
    "# Multiple ways of Setting and Getting of Gears configs\n",
    "max_exec_orig = single.gears.config.MaxExecutions\n",
    "single.gears.config.MaxExecutions = 2000\n",
    "\n",
    "send_msg_retries = single.gears.config.get(\"SendMsgRetries\")\n",
    "\n",
    "single.gears.config.set(SendMsgRetries=4,  MaxExecutions=max_exec_orig)\n",
    "\n",
    "all_configs = single.gears.config.get()\n",
    "\n",
    "print(basic_gear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b\"{'event': None, 'key': '/license/4', 'type': 'hash', 'value': {'name': 'Attribution License', 'url': 'http://creativecommons.org/licenses/by/2.0/', 'id': '4'}}\",\n",
       " b\"{'event': None, 'key': '/license/8', 'type': 'hash', 'value': {'name': 'United States Government Work', 'url': 'http://www.usa.gov/copyright.shtml', 'id': '8'}}\",\n",
       " b\"{'event': None, 'key': '/license/1', 'type': 'hash', 'value': {'name': 'Attribution-NonCommercial-ShareAlike License', 'url': 'http://creativecommons.org/licenses/by-nc-sa/2.0/', 'id': '1'}}\",\n",
       " b\"{'event': None, 'key': '/license/5', 'type': 'hash', 'value': {'name': 'Attribution-ShareAlike License', 'url': 'http://creativecommons.org/licenses/by-sa/2.0/', 'id': '5'}}\",\n",
       " b\"{'event': None, 'key': '/license/3', 'type': 'hash', 'value': {'name': 'Attribution-NonCommercial-NoDerivs License', 'url': 'http://creativecommons.org/licenses/by-nc-nd/2.0/', 'id': '3'}}\",\n",
       " b\"{'event': None, 'key': '/license/6', 'type': 'hash', 'value': {'name': 'Attribution-NoDerivs License', 'url': 'http://creativecommons.org/licenses/by-nd/2.0/', 'id': '6'}}\",\n",
       " b\"{'event': None, 'key': '/license/2', 'type': 'hash', 'value': {'name': 'Attribution-NonCommercial License', 'url': 'http://creativecommons.org/licenses/by-nc/2.0/', 'id': '2'}}\",\n",
       " b\"{'event': None, 'key': '/license/7', 'type': 'hash', 'value': {'name': 'No known copyright restrictions', 'url': 'http://flickr.com/commons/usage/', 'id': '7'}}\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.gears.pyexecute(\"GB('KeysReader').run('/license/*')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-query\"></a>\n",
    "## 2. Simple Analytics Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Demo 2 - Analytical Query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-stream\"></a>\n",
    "## 3. Transaction Stream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Demo 3 - Transaction Stream Processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-command\"></a>\n",
    "## 4. Custom Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Demo 4 - Custom Command\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "dab300696de9719b5a13d46921259e062f63d9f082fc9b215a0fc3675193508b"
   }
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
