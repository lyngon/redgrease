{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedGrease Demo at RedisConf 2021\n",
    "\n",
    "Quick demonstration of how to create and run Redis Gears functions, using RedGrease.\n",
    "\n",
    "## [Demos](#Demos):\n",
    "1. [The Basics](#1.-The-Basics)\n",
    "2. [Simple Analytics Query](#2.-Simple-Analytics-Query)\n",
    "3. [Transaction Stream Processing](#3.-Transaction-Stream-Processing)\n",
    "4. [Custom Command](#4.-Custom-Command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations\n",
    "Before running the demos, make sure that the prerequisites are met and that the preparation steps have successfully been executed. \n",
    "Some preparation steps, particularly the downloads, may take quite some time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n",
    "- Python3.7\n",
    "- Pip\n",
    "- Docker\n",
    "- Jupyter\n",
    "\n",
    "Run the cell below tho validate your prerequisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell to test your environment requirements\n",
    "\n",
    "import sys\n",
    "import re\n",
    "pyver = !{sys.executable} --version  # type: ignore\n",
    "pipver = !{sys.executable} -m pip --version  # type: ignore\n",
    "dockver = !docker --version  # type: ignore\n",
    "\n",
    "if not re.match(\"Python 3.7\", pyver[0]):\n",
    "    raise SystemExit(f\"This demo only supports Python 3.7. You are running {pyver[0]}.\")\n",
    "\n",
    "if not re.match(\".*\\(python 3.7\\)\", pipver[0]):\n",
    "    raise SystemExit(\"Please install Pip for yout Python 3.7 environment.\")\n",
    "\n",
    "if not re.match(\"Docker version\", dockver[0]):\n",
    "    raise SystemExit(\"Please install Docker\")\n",
    "\n",
    "print(\"Requirements all look good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python Requirements\n",
    "\n",
    "Install the Python packages required for the demo:\n",
    "\n",
    "- `redgrease[client]` - The RedGrease client library for Redis Gears. This is what is being demonstrated.\n",
    "\n",
    "- `ipywidgets` - Jupyter notebook exetension, for displaying widgets, e.g. buttons, in this notebook.\n",
    "- `requests` - For downloading content.\n",
    "\n",
    "Run the cell below to install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture reqs_install_output\n",
    "!{sys.executable} -m pip install redgrease[client] ipywidgets requests\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Datasets\n",
    "Some of the demos requiere a portion of the [COCO Dataset](https://cocodataset.org) to be uploaded into the Redis Gears Cluster.\n",
    "The COCO Dataset (Common Objects in Context) is a fairly large set of (~247,000) images and corresponding annotations of what tey are depicting.\n",
    "\n",
    "### Example:\n",
    "<img src=\"coco_example.jpg\" > [COCO Example](coco_example.jpg)\n",
    "\n",
    "```\n",
    "a man riding a snowboard down a ski slope.\n",
    "a snowboarder sailing down a snowy hillside on a mountain.\n",
    "a man is snowboarding past blue markers on a mountain.\n",
    "a man on a snowboard in the snow.\n",
    "a man snow boarding in the snow on a slope. \n",
    "```\n",
    "\n",
    "\n",
    "For the demo we will only pre-download the annotations (json), not the images (jpeg), but it is still between 250 - 500 MB of data, depending on which portions you choose.\n",
    "\n",
    "There are two annotation packages to choose from. \n",
    "- **COCO Train/Cal 2014** - Annotations for 124,000 images (241 MB)\n",
    "- **COCO Train/Val 2017** - Annotations for 123,000 images (241 MB)\n",
    "\n",
    "Either or both may be used. \n",
    "Run the cell below and select using the buttons which dataset(s) to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is just for preparation of the demo.\n",
    "# It is NOT part of the demo itself\n",
    "#\n",
    "# Download COCO Annotations \n",
    "# Run the cell, then:\n",
    "# - Validate or modify the Download directory\n",
    "# - Click the button, or buttons for the annotations to download\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import requests\n",
    "\n",
    "coco_annotations_url = \"http://images.cocodataset.org/annotations\"\n",
    "annotations_file_pattern = \"annotations_trainval{}.zip\"\n",
    "\n",
    "layout = widgets.Layout(width=\"30%\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def get_download_path():\n",
    "    download_dir = \".\"\n",
    "    if os.name == 'nt':\n",
    "        import winreg\n",
    "        sub_key = r'SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders'\n",
    "        downloads_guid = '{374DE290-123F-4565-9164-39C4925E467B}'\n",
    "        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, sub_key) as key:\n",
    "            download_dir = winreg.QueryValueEx(key, downloads_guid)[0]\n",
    "    else:\n",
    "        download_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "\n",
    "    return os.path.join(download_dir, \"COCO\")\n",
    "\n",
    "download_location = widgets.Text(\n",
    "    value=get_download_path(),\n",
    "    placeholder=\"Download directory\",\n",
    "    description=\"Directory to download annotations to.\",\n",
    "    layout=layout,\n",
    ")\n",
    "display(download_location)\n",
    "\n",
    "def dl_state(button, downloading=None):\n",
    "    year = button.value\n",
    "    annotations_file_name = annotations_file_pattern.format(year)\n",
    "    destination = os.path.join(download_location.value, annotations_file_name)\n",
    "    is_downloaded = os.path.isfile(destination)\n",
    "    button.disabled = is_downloaded or downloading is not None\n",
    "    if downloading:\n",
    "        button.description=f\"Downloading COCO {year} annotations (241 MB): {downloading}%. Please wait!\"\n",
    "    elif is_downloaded:\n",
    "        button.description=f\"Congrats! COCO {year} annotataions is downloaded!\"\n",
    "    else:\n",
    "        button.description=f\"Download COCO {year} annotations (241 MB)\"\n",
    "    return is_downloaded, annotations_file_name, destination\n",
    "\n",
    "\n",
    "def download_button_pressed(btn):\n",
    "    downloaded, file_name, destination = dl_state(btn)\n",
    "    if downloaded:\n",
    "        return\n",
    "    if not os.path.isdir(download_location.value):\n",
    "        os.mkdir(download_location.value)\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{coco_annotations_url}/{file_name}\",\n",
    "            stream=True\n",
    "        )\n",
    "        total_length = response.headers.get('content-length')\n",
    "        with open(destination, \"wb\") as f:\n",
    "            if total_length is None: # no content length header\n",
    "                dl_state(btn, \"???\")\n",
    "                f.write(response.content)\n",
    "                return\n",
    "            total_length = int(total_length)\n",
    "            dl = 0\n",
    "            for data in response.iter_content(chunk_size=4096):\n",
    "                dl += len(data)\n",
    "                f.write(data)\n",
    "                dl_state(btn, int(100*(dl/total_length)))\n",
    "\n",
    "    except Exception:\n",
    "        try:\n",
    "            os.remove(destination)\n",
    "        except Exception:\n",
    "            pass\n",
    "    finally:\n",
    "        dl_state(btn)\n",
    "\n",
    "for year in [\"2014\", \"2017\"]:\n",
    "    download_button = widgets.Button(\n",
    "        tooltip='Start download of selected datasets into the selected download directory.',\n",
    "        layout=layout\n",
    "    )\n",
    "    download_button.value = year\n",
    "    dl_state(download_button)\n",
    "    download_button.on_click(download_button_pressed)\n",
    "    display(download_button)\n",
    "\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download and run Redis Gears Cluster Docker image\n",
    "Run the cell below to download a Redis Gears Cluster Docker image (~605 MB), if not already present, and run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_gears_cluster_image = \"redislabs/rgcluster:1.0.6\"\n",
    "redis_gears_cluster_container_name = \"demo_gears_cluster\"\n",
    "\n",
    "redis_gears_single_image = \"redislabs/redisgears:1.0.6\"\n",
    "redis_gears_single_container_name = \"demo_gears_single\"\n",
    "\n",
    "# Get the correct Redis Gears Images\n",
    "!docker pull {redis_gears_single_image}\n",
    "!docker pull {redis_gears_cluster_image}\n",
    "\n",
    "# Check if the single container is already running.\n",
    "container_info = !docker container inspect {redis_gears_single_container_name}\n",
    "if container_info[0] == \"[]\":\n",
    "    print(\"Starting Redis Gears single instance\")\n",
    "    !docker run --name {redis_gears_single_container_name} --rm -d -p 6379:6379 {redis_gears_single_image}\n",
    "\n",
    "\n",
    "# Check if the cluster container is already running.\n",
    "container_info = !docker container inspect {redis_gears_cluster_container_name}\n",
    "if container_info[0] == \"[]\":\n",
    "    print(\"Starting Redis Gears cluster instance\")\n",
    "    !docker run --name {redis_gears_cluster_container_name} --rm -d -p 30001:30001 -p 30002:30002 -p 30003:30003 {redis_gears_cluster_image}\n",
    "\n",
    "print(\"Redis Gears containers are running!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Annotation Data into Redis cluster\n",
    "By running the cell below, the COCO annotations downloaded above will be loaded into the Redis Cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import redgrease\n",
    "import zipfile\n",
    "\n",
    "annotation_archive_files = os.path.join(download_location.value, \"annotations_trainval*.zip\")\n",
    "annotation_archives = glob.glob(annotation_archive_files)\n",
    "\n",
    "if not annotation_archives:\n",
    "    print(\"no archives\")\n",
    "    raise SystemExit(\"Please download either or both COCO annotations as per instructions above.\")\n",
    "\n",
    "r = redgrease.RedisGears(host=\"localhost\", port=30001)\n",
    "\n",
    "annotation_json_pattern = re.compile(\"annotations/(\\w+)_([a-zA-Z]+)([0-9]+).json\")\n",
    "\n",
    "annotation_types = [\"instances\", \"person_keypoints\", \"captions\"]\n",
    "years = [\"2014\", \"2017\"]\n",
    "purpose = [\"val\", \"train\"]\n",
    "\n",
    "output = widgets.Output()\n",
    "progress = widgets.Text(\"\", layout=layout)\n",
    "\n",
    "def load_annotation_info(base_key, info):\n",
    "    annotation_info_key = f\"{base_key}/info\"\n",
    "    r.hset(annotation_info_key, mapping=info)\n",
    "    return annotation_info_key\n",
    "\n",
    "def load_license_info(base_key, license):\n",
    "    license_key = f\"{base_key}/license/{license['id']}\"\n",
    "    if not r.exists(license_key):\n",
    "        r.hset(license_key, mapping=license)\n",
    "    return license_key\n",
    "\n",
    "def load_image_info(base_key, image_info):\n",
    "    img_info_key = f\"{base_key}/image/{image_info['id']}/info\"\n",
    "    if not r.exists(img_info_key):\n",
    "        r.hset(img_info_key, mapping=image_info)\n",
    "    return img_info_key\n",
    "\n",
    "def load_keypoint_names(base_key, keypoints):\n",
    "    keypoints_key = f\"{base_key}/keypoints\"\n",
    "    r.lpush(keypoints_key, *keypoints)\n",
    "    return keypoints_key\n",
    "\n",
    "def load_list_of_str(base_key, sequence):\n",
    "    list_key = f\"{base_key}/skeleton\"\n",
    "    r.lpush(list_key, *map(str, sequence))\n",
    "    return list_key\n",
    "\n",
    "def load_category(base_key, category):\n",
    "    category_key = f\"{base_key}/category/{category['id']}\"\n",
    "\n",
    "    if \"keypoints\" in category:\n",
    "        category[\"keypoints\"] = load_keypoint_names(category_key, category[\"keypoints\"])\n",
    "    if \"skeleton\" in category:\n",
    "        category[\"skeleton\"] = load_list_of_str(category_key, category[\"skeleton\"])\n",
    "\n",
    "    r.hset(category_key, mapping=category)\n",
    "    return category_key\n",
    "\n",
    "def load_segmentation(base_key, segmentation):\n",
    "    segmentation_key = f\"{base_key}/segmentation\"\n",
    "    if not r.exists(segmentation_key):\n",
    "        for i, segment in enumerate(segmentation):\n",
    "            segment_key = f\"{segmentation_key}/{i}\"\n",
    "            r.lpush(segment_key, *segment)\n",
    "            r.rpush(segmentation_key, segment_key)\n",
    "    return segmentation_key\n",
    "\n",
    "def load_annotation(base_key, annotation):\n",
    "    \n",
    "    annotation_key = f\"{base_key}/image/{annotation['image_id']}/annotation/{annotation['id']}\"\n",
    "    \n",
    "    if not r.exists(annotation_key):\n",
    "        if \"segmentation\" in annotation:\n",
    "            # Replace the 'segmentation' list-of-lists, with a key with a list of keys, that in turn point to the inner lists :)\n",
    "            annotation[\"segmentation\"] = load_segmentation(annotation_key, annotation[\"segmentation\"])\n",
    "        \n",
    "        if \"bbox\" in annotation:\n",
    "            # Replace the 'bbox' with a string reepresentaton.load_segmentation\n",
    "            annotation[\"bbox\"] = str(annotation[\"bbox\"])\n",
    "\n",
    "        if \"keypoints\" in annotation:\n",
    "            annotation[\"keypoints\"] = load_list_of_str(annotation_key, annotation[\"keypoints\"])\n",
    "\n",
    "        r.hset(annotation_key, mapping=annotation)\n",
    "    return annotation_key\n",
    "\n",
    "def load_annotation_jsons_from_zip(zip_file):\n",
    "    with zipfile.ZipFile(zip_file) as archive:\n",
    "        for file_name in archive.namelist():\n",
    "            is_annotation_file = annotation_json_pattern.match(file_name)\n",
    "            if not is_annotation_file:\n",
    "                continue\n",
    "            \n",
    "            annotation_type = is_annotation_file.group(1)\n",
    "            dataset_purpose = is_annotation_file.group(2)\n",
    "            dataset_year = is_annotation_file.group(3)\n",
    "\n",
    "            if not annotation_type in annotation_types:\n",
    "                continue\n",
    "            \n",
    "            if not dataset_purpose in purpose:\n",
    "                continue\n",
    "                \n",
    "            if not dataset_year in years:\n",
    "                continue\n",
    "\n",
    "            with archive.open(file_name) as json_file:\n",
    "                contents = json.load(json_file)\n",
    "    \n",
    "            base_key = f\"/dataset/coco/{dataset_year}\"\n",
    "            info_key = f\"{base_key}/general/{annotation_type}/{dataset_purpose}\"\n",
    "                \n",
    "            # info\n",
    "            if \"info\" in contents:\n",
    "                progress.value = f\"Loading info for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                load_annotation_info(info_key, contents[\"info\"])\n",
    "\n",
    "            # licenses\n",
    "            if \"licenses\" in contents:\n",
    "                progress.value = f\"Loading licenses for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                for lic in contents[\"licenses\"]:\n",
    "                    load_license_info(info_key, lic)\n",
    "                    \n",
    "            # images\n",
    "            if \"images\" in contents:\n",
    "                progress.value = f\"Loading images for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                for image_info in contents[\"images\"]:\n",
    "                    load_image_info(base_key, image_info)\n",
    "\n",
    "            # annotations\n",
    "            if \"annotations\" in contents:\n",
    "                progress.value = f\"Loading annotations for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                for annotation in contents[\"annotations\"]:\n",
    "                    load_annotation(base_key, annotation)\n",
    "\n",
    "            # categories (for \"instances\" and \"person_keypoints\")\n",
    "            if \"categories\" in contents:\n",
    "                progress.value = f\"Loading categories for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                for category in contents[\"categories\"]:\n",
    "                    load_category(base_key, category)\n",
    "\n",
    "            \n",
    "display(progress)\n",
    "for archive in annotation_archives:\n",
    "    progress.value = f\"Unzipping {archive}\"\n",
    "    load_annotation_jsons_from_zip(archive)\n",
    "progress.value = \"Done!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.flushall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos\n",
    "This is the actual Demo section. Everything above is just preparations.\n",
    "\n",
    "1. [The Basics](#1.-The-Basics)\n",
    "2. [Simple Analytics Query](#2.-Simple-Analytics-Query)\n",
    "3. [Transaction Stream Processing](#3.-Transaction-Stream-Processing)\n",
    "4. [Custom Command](#4.-Custom-Command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demm-basics\"></a>\n",
    "## 1. The Basics\n",
    "Showcasing some of the basic features and commands of the redgrease package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redgrease\n",
    "import redgrease.utils\n",
    "\n",
    "# Create connection / client for single instance Redis\n",
    "single = redgrease.RedisGears() \n",
    "\n",
    "# Create connectoin / client for Redis Cluster \n",
    "cluster = redgrease.RedisGears(\n",
    "    startup_nodes=[\n",
    "        {\"host\":\"localhost\", \"port\":30001},\n",
    "        {\"host\":\"localhost\", \"port\":30002},\n",
    "        {\"host\":\"localhost\", \"port\":30003},\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual Redis commands work as expected\n",
    "a = single.flushall()\n",
    "b = single.set(\"Foo\", 21)\n",
    "c = single.hset(\"Bar\", mapping={\"spam\":\"eggs\", \"meaning\":8})\n",
    "d = single.hincrby(\"Bar\", \"meaning\", 34)\n",
    "e = single.xadd(\"tlogs::0\", {\"msg\":\"START\", \"from\":0, \"to\":0, \"amount\":0})\n",
    "\n",
    "a, b, c, d, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gears commands can be accessed through the 'gears' attribute\n",
    "\n",
    "cluster_pystats = cluster.gears.pystats()\n",
    "\n",
    "print(f\"Cluster Redis - Python Stats:\\n{cluster_pystats}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "cluster_info = cluster.gears.infocluster()\n",
    "\n",
    "print(f\"Cluster Redis - Cluster Info:\\n{cluster_info}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "cluster_refreshed = cluster.gears.refreshcluster()\n",
    "\n",
    "print(f\"Cluster Redis - Cluster Refresh Response:\\n{cluster_refreshed}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "single_pystats = single.gears.pystats()\n",
    "\n",
    "print(f\"Single-node Redis - Python Stats:\\n{single_pystats}\\n\")\n",
    "\n",
    "\n",
    "# Iterate through all Redis key-value records, and return all record data.\n",
    "all_records_gear = single.gears.pyexecute(\"GearsBuilder().run()\")\n",
    "\n",
    "print(\"Single-node Redis - All-records gear: [\")\n",
    "for result in all_records_gear:\n",
    "    print(f\"  {result}\")\n",
    "print(\"]\\n\")\n",
    "\n",
    "\n",
    "# Iterate through all Redis key-value records, and return just the key and type\n",
    "key_type_gear = single.gears.pyexecute(\"GearsBuilder().map(lambda record:(record['key'], record['type'])).run()\")\n",
    "\n",
    "\n",
    "print(\"Single-node Redis - Key-types gear: [\")\n",
    "for result in key_type_gear:\n",
    "    print(f\"  {result}\")\n",
    "print(\"]\\n\")\n",
    "\n",
    "\n",
    "single_record_count = single.gears.pyexecute(\"GearsBuilder().count().run()\")\n",
    "print(f\"Single-node Redis - Record count: {single_record_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of python functions as strings\n",
    "RedGrease allows for cunstruction of GearFuntion objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_count = redgrease.KeysOnlyReader().count().run()\n",
    "\n",
    "cluster_record_count = cluster.gears.pyexecute(record_count)\n",
    "\n",
    "print(f\"Cluster Redis - Total records: {cluster_record_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GearFunctions lets you compose and reuse partial functions\n",
    "images = redgrease.KeysReader(\"/dataset/coco/*/image/*/info\").map(lambda record: record['value'])\n",
    "\n",
    "image_count = images.count()\n",
    "\n",
    "square_images = images.filter(lambda img: img['height'] == img['width'])\n",
    "\n",
    "some_image_urls = square_images.collect().limit(4).map(lambda record: record['coco_url'])\n",
    "\n",
    "def instance_annotations(year=\"*\"):\n",
    "    return (\n",
    "        redgrease.KeysReader(f\"/dataset/coco/{year}/image/*/annotation/*\")\n",
    "        .filter(lambda record: record['type'] == \"hash\")\n",
    "        .map(lambda record: record[\"value\"])\n",
    "    )\n",
    "\n",
    "# Different ways of running\n",
    "img_cnt = image_count.run(on=cluster)\n",
    "img_portrait = square_images.run().on(cluster)\n",
    "\n",
    "annotation_cnt = cluster.gears.pyexecute(instance_annotations().count().run())\n",
    "img_urls = cluster.gears.pyexecute(some_image_urls)\n",
    "\n",
    "\n",
    "print(f\"Total number of images: {img_cnt}\\n\")\n",
    "print(f\"Total number of annotations: {annotation_cnt}\\n\")\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "print(f\"Some square images\")\n",
    "for img_url in img_urls:\n",
    "    display(Image(url=img_url))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-query\"></a>\n",
    "## 2. Simple Analytics Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_merge(d1, d2):\n",
    "    return {**d1, **d2}\n",
    "\n",
    "get_category_ids = (\n",
    "    redgrease.KeysReader(\"/dataset/*/category/*\")\n",
    "    .map(lambda record: {record['value']['name']:record['value']['id']})\n",
    "    .aggregate({},dict_merge, dict_merge)\n",
    ")\n",
    "\n",
    "get_category_names = (\n",
    "    redgrease.KeysReader(\"/dataset/*/category/*\")\n",
    "    .map(lambda record: {record['value']['id']:record['value']['name']})\n",
    "    .aggregate({},dict_merge, dict_merge)\n",
    ")\n",
    "                         \n",
    "category_id_lookup = get_category_ids.run(on=cluster)\n",
    "category_name_lookup = get_category_names.run(on=cluster)\n",
    "category_id_lookup, len(category_id_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def accumulate_categories(image_id, accumulator, annotation):    \n",
    "    annotation_category_id = annotation.get('category_id',-1)\n",
    "    accumulator[annotation_category_id] = accumulator.get(annotation_category_id, 0) + 1\n",
    "    \n",
    "    return accumulator\n",
    "\n",
    "\n",
    "def accumulate_category_counts(image_id, accumulator, category_count):\n",
    "    for category, count in category_count.items():\n",
    "        accumulator[category] = accumulator.get(category, 0) + count\n",
    "    return accumulator\n",
    "\n",
    "\n",
    "def format_img_stats(img_stats):\n",
    "    return {\n",
    "        'image_id': img_stats['key'],\n",
    "        'instances': img_stats['value']\n",
    "    }\n",
    "\n",
    "category_count_by_image = instance_annotations(2017).aggregateby(\n",
    "    extractor = lambda annotation : annotation.get('image_id', -1),\n",
    "    zero = {},\n",
    "    seqOp = accumulate_categories,\n",
    "    combOp = accumulate_category_counts\n",
    ").map(format_img_stats)\n",
    "\n",
    "c = category_count_by_image.limit(10).run(on=cluster)\n",
    "len(c), c, c.errors\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contstrain(constraints):\n",
    "    # return a predicate for instance counts where the count of a set of categories\n",
    "    # Constraints is a dict from category name to a tuple of (min_count, max_count)\n",
    "    \n",
    "    id_constraints = { category_id_lookup[cat_name]:x for cat_name, x in constraints.items()}\n",
    "    \n",
    "    def predicate(record):\n",
    "        instances = record['instances']\n",
    "        \n",
    "        for cat_id, constraint in id_constraints.items():\n",
    "            min_count, max_count = constraint\n",
    "            \n",
    "            if cat_id not in instances:\n",
    "                if min_count is not ... and min_count > 0:\n",
    "                    return False\n",
    "                continue\n",
    "            \n",
    "            if min_count is not ... and instances[cat_id] < min_count:\n",
    "                return False\n",
    "            \n",
    "            if max_count is not ... and instances[cat_id] > max_count:\n",
    "                return False\n",
    "            \n",
    "        return True\n",
    "\n",
    "    return predicate\n",
    "    \n",
    "query_params = {\n",
    "    'banana': [5, ...],\n",
    "    'person': [1, 1],\n",
    "    'orange': [..., 0],\n",
    "    'truck': [1, 2],\n",
    "}\n",
    "\n",
    "\n",
    "query = category_count_by_image.filter(contstrain(query_params))\n",
    "\n",
    "query_result = query.limit(30).run(on=cluster)\n",
    "\n",
    "query_result, query_result.errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.count().run(on=cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_ids = [result['image_id'] for result in query_result]\n",
    "\n",
    "image_urls = (\n",
    "    redgrease.KeysReader(\"/dataset/coco/2017/image/*/info\")\n",
    "    .map(lambda record: record['value'])\n",
    "    .filter(lambda img: img['id'] in image_ids)\n",
    "    .map(lambda img: img[\"coco_url\"])\n",
    "    .run(on=cluster)\n",
    ")\n",
    "\n",
    "for image_url in image_urls:\n",
    "    display(Image(url=image_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-stream\"></a>\n",
    "## 3. Transaction Stream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity 0 balance: 380  (0)\n",
      "Entity 1 balance: 497  (0)\n",
      "Entity 2 balance: 794  (0)\n",
      "Entity 3 balance: 769  (0)\n",
      "Entity 4 balance: 837  (0)\n",
      "----------------------------\n",
      "Total balance   : 3277\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "entity_count = 5\n",
    "min_start_balance = 100\n",
    "max_start_balance = 1000\n",
    "\n",
    "\n",
    "# Create some accounts\n",
    "for entity_id in range(entity_count):\n",
    "    start_balance = random.randint(min_start_balance, max_start_balance)\n",
    "    single.hset(\n",
    "        f\"/entity/{entity_id}\",\n",
    "        mapping={\n",
    "            \"id\": entity_id, \n",
    "            \"balance\": start_balance,\n",
    "            \"start_balance\": start_balance,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "def attempt_random_transaction(channel, max_amount=100, message=\"This is a random transaction\",):\n",
    "    single.xadd(\n",
    "        f\">>transactions:{channel}\", \n",
    "        {\n",
    "            \"msg\": message, \n",
    "            \"from\": random.randint(0, entity_count-1), \n",
    "            \"to\": random.randint(0, entity_count-1), \n",
    "            \"amount\": random.randint(1, max_amount),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    \n",
    "def balance_sheet():\n",
    "    sum_balance = 0\n",
    "    for entity_id in range(entity_count):\n",
    "        current_balance, start_balance = map(int, single.hmget(f\"/entity/{entity_id}\", \"balance\", \"start_balance\"))\n",
    "        print(f\"Entity {entity_id} balance: {current_balance}  ({current_balance-start_balance})\")\n",
    "        sum_balance += current_balance\n",
    "    print(\"----------------------------\")\n",
    "    print(f\"Total balance   : {sum_balance}\")\n",
    "    return sum_balance\n",
    "\n",
    "start_total_balance = balance_sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExecutionResult[bool](True)"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Transform a key-space event to a transaction\n",
    "def to_transaction(event):\n",
    "    transaction = event['value']\n",
    "    transaction['channel'] = event['key']\n",
    "    transaction['id'] = event['id']\n",
    "    return transaction\n",
    "    \n",
    "# Register the tranaction on its own unique key.\n",
    "def register_transaction(transaction):\n",
    "    transaction['status'] = \"pending\"\n",
    "    redgrease.cmd.hset(\n",
    "        f\"/status/{transaction['channel']}/{transaction['id']}\",\n",
    "        mapping=transaction\n",
    "    )\n",
    "\n",
    "    \n",
    "# Handle the transaction safely\n",
    "def handle_transaction(transaction):\n",
    "    \n",
    "    # Log the transaction event to the Redis engine log\n",
    "    redgrease.log(f\"Procesing transaction {transaction['id']}: {transaction}\")\n",
    "    \n",
    "    # Perform a sequence of commands atomically\n",
    "    with redgrease.atomic():\n",
    "        \n",
    "        # Check if the 'sender' has sufficient balance\n",
    "        sender_balance = redgrease.cmd.hget(\n",
    "                f\"/entity/{transaction['from']}\",\n",
    "                \"balance\"\n",
    "            )\n",
    "        amount = int(transaction.get('amount', 0))\n",
    "        \n",
    "        if not sender_balance or amount > int(sender_balance):\n",
    "            # If balance is not sufficient, the transaction is marked as failed.\n",
    "            transaction['status'] = f\"FAILED: Missing {int(sender_balance)-amount}\"\n",
    "            \n",
    "        else:                      \n",
    "            # If there is sufficient balance, \n",
    "            # remove the amount from sender and add it to the recipient\n",
    "            # and mark as successful\n",
    "            redgrease.cmd.hincrby(\n",
    "                f\"/entity/{transaction['from']}\",\n",
    "                \"balance\",\n",
    "                -amount\n",
    "            )\n",
    "            redgrease.cmd.hincrby(\n",
    "                f\"/entity/{transaction['to']}\",\n",
    "                \"balance\",\n",
    "                amount\n",
    "            )\n",
    "            transaction['status'] = \"successful\"\n",
    "        \n",
    "    # Update the transaction status\n",
    "    redgrease.cmd.hset(\n",
    "        f\"/status/{transaction['channel']}/{transaction['id']}\",\n",
    "        \"status\",\n",
    "        transaction['status']\n",
    "    )\n",
    "    redgrease.log(f\"Done processing transaction {transaction['id']}: {transaction['status']}\")\n",
    "    return transaction\n",
    "\n",
    "def handle_unsuccessful_transaction(transaction):\n",
    "    redgrease.log(f\"Handling rejected transaction {transaction['id']}: {transaction}\")\n",
    "    redgrease.cmd.xadd(\">>rejected\", transaction)\n",
    "\n",
    "    \n",
    "import uuid\n",
    "def dump_to(key):\n",
    "    def dump(x):\n",
    "        redgrease.cmd.hset(f\"{key}::{uuid.uuid4()}\", mapping=dict(x))\n",
    "    return dump\n",
    "    \n",
    "    \n",
    "    \n",
    "# Transaction processing pipeline\n",
    "transsaction_pipe = (\n",
    "    redgrease.StreamReader()  # Listen to streams\n",
    "    .map(to_transaction)  # Map events to a 'transaction' dict\n",
    "    .foreach(register_transaction)  # Register the transactions as 'pending'\n",
    "    .map(handle_transaction)  # Execute the transaction\n",
    "    .filter(lambda transaction: transaction['status'] != \"successful\") # Get the transactions that didn't succeed\n",
    "    .foreach(handle_unsuccessful_transaction) # Pretend to handle \"appropriately\"\n",
    "    .register(prefix=\">>transactions:*\", batch=10, duration=30) # Listen to transaction stream and use batching\n",
    ")\n",
    "\n",
    "\n",
    "# Register the processing pipeline\n",
    "transsaction_pipe.on(single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Gear function 0000000000000000000000000000000000000000-58 has been triggered 0 times.\n"
     ]
    }
   ],
   "source": [
    "for registration in single.gears.dumpregistrations():\n",
    "    print(f\"Registered Gear function {registration.id} has been triggered {registration.RegistrationData.numTriggered} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt_random_transaction(\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity 0 balance: 337  (-43)\n",
      "Entity 1 balance: 497  (0)\n",
      "Entity 2 balance: 837  (43)\n",
      "Entity 3 balance: 769  (0)\n",
      "Entity 4 balance: 837  (0)\n",
      "----------------------------\n",
      "Total balance   : 3277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3277"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import repeat\n",
    "\n",
    "# Run a bunch of transactions in parallell\n",
    "parallell_transaction_jobs = 100\n",
    "sequential_transactions_count = 100\n",
    "max_transaction_amount = 500 \n",
    "\n",
    "def sequential_transactions(channel=\"foo\"):\n",
    "    def attempt_transactions():\n",
    "        for transaction_id in range(sequential_transactions_count):\n",
    "            attempt_random_transaction(\n",
    "                channel, \n",
    "                max_amount=max_transaction_amount,\n",
    "                message=f\"This is a transaction #{transaction_id} on channel {channel}\",\n",
    "            )\n",
    "    return attempt_transactions\n",
    "    \n",
    "def run_in_parallell(jobs):\n",
    "    with ThreadPoolExecutor() as worker:\n",
    "        tasks = [worker.submit(job) for job in jobs]\n",
    "\n",
    "jobs = [ sequential_transactions(nm) for nm in range(parallell_transaction_jobs)]\n",
    "        \n",
    "run_in_parallell(jobs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity 0 balance: 78  (-302)\n",
      "Entity 1 balance: 118  (-379)\n",
      "Entity 2 balance: 145  (-649)\n",
      "Entity 3 balance: 2062  (1293)\n",
      "Entity 4 balance: 874  (37)\n",
      "----------------------------\n",
      "Total balance   : 3277\n",
      "Total difference: 0\n",
      "\n",
      "Registered Gear function 0000000000000000000000000000000000000000-58 has been triggered 1793 times.\n"
     ]
    }
   ],
   "source": [
    "end_total_balance = balance_sheet()\n",
    "print(f\"Total difference: {start_total_balance - end_total_balance}\")\n",
    "print()\n",
    "for registration in single.gears.dumpregistrations():\n",
    "    print(f\"Registered Gear function {registration.id} has been triggered {registration.RegistrationData.numTriggered} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsuccessful transaction: b\"{'to': '2', 'from': '2', 'msg': 'This is a transaction #83 on channel 97', 'amount': '374', 'channel': '>>transactions:97', 'id': '1616675582825-1', 'status': 'FAILED: Missing -276'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '1', 'msg': 'This is a transaction #86 on channel 97', 'amount': '496', 'channel': '>>transactions:97', 'id': '1616675582831-1', 'status': 'FAILED: Missing -5'}\"\n",
      "Unsuccessful transaction: b\"{'to': '1', 'from': '1', 'msg': 'This is a transaction #73 on channel 99', 'amount': '374', 'channel': '>>transactions:99', 'id': '1616675582809-0', 'status': 'FAILED: Missing -360'}\"\n",
      "Unsuccessful transaction: b\"{'to': '1', 'from': '1', 'msg': 'This is a transaction #75 on channel 99', 'amount': '455', 'channel': '>>transactions:99', 'id': '1616675582811-0', 'status': 'FAILED: Missing -441'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '1', 'msg': 'This is a transaction #77 on channel 99', 'amount': '381', 'channel': '>>transactions:99', 'id': '1616675582816-1', 'status': 'FAILED: Missing -261'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '1', 'msg': 'This is a transaction #78 on channel 99', 'amount': '325', 'channel': '>>transactions:99', 'id': '1616675582818-0', 'status': 'FAILED: Missing -205'}\"\n",
      "Unsuccessful transaction: b\"{'to': '0', 'from': '0', 'msg': 'This is a transaction #93 on channel 95', 'amount': '217', 'channel': '>>transactions:95', 'id': '1616675582835-1', 'status': 'FAILED: Missing -139'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '1', 'msg': 'This is a transaction #97 on channel 95', 'amount': '280', 'channel': '>>transactions:95', 'id': '1616675582837-1', 'status': 'FAILED: Missing -222'}\"\n",
      "Unsuccessful transaction: b\"{'to': '0', 'from': '1', 'msg': 'This is a transaction #99 on channel 95', 'amount': '116', 'channel': '>>transactions:95', 'id': '1616675582838-0', 'status': 'FAILED: Missing -58'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '0', 'msg': 'This is a transaction #93 on channel 97', 'amount': '356', 'channel': '>>transactions:97', 'id': '1616675582836-0', 'status': 'FAILED: Missing -278'}\"\n",
      "Unsuccessful transaction: b\"{'to': '0', 'from': '0', 'msg': 'This is a transaction #98 on channel 97', 'amount': '337', 'channel': '>>transactions:97', 'id': '1616675582838-0', 'status': 'FAILED: Missing -259'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '0', 'msg': 'This is a transaction #99 on channel 97', 'amount': '476', 'channel': '>>transactions:97', 'id': '1616675582838-1', 'status': 'FAILED: Missing -398'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '4', 'msg': 'This is a transaction #60 on channel 99', 'amount': '455', 'channel': '>>transactions:99', 'id': '1616675582785-0', 'status': 'FAILED: Missing -328'}\"\n",
      "Unsuccessful transaction: b\"{'to': '3', 'from': '4', 'msg': 'This is a transaction #61 on channel 99', 'amount': '375', 'channel': '>>transactions:99', 'id': '1616675582785-1', 'status': 'FAILED: Missing -248'}\"\n",
      "Unsuccessful transaction: b\"{'to': '0', 'from': '1', 'msg': 'This is a transaction #62 on channel 99', 'amount': '190', 'channel': '>>transactions:99', 'id': '1616675582787-0', 'status': 'FAILED: Missing -158'}\"\n",
      "Unsuccessful transaction: b\"{'to': '1', 'from': '2', 'msg': 'This is a transaction #65 on channel 99', 'amount': '476', 'channel': '>>transactions:99', 'id': '1616675582792-0', 'status': 'FAILED: Missing -302'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '2', 'msg': 'This is a transaction #67 on channel 99', 'amount': '376', 'channel': '>>transactions:99', 'id': '1616675582801-0', 'status': 'FAILED: Missing -202'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '4', 'msg': 'This is a transaction #68 on channel 99', 'amount': '486', 'channel': '>>transactions:99', 'id': '1616675582802-0', 'status': 'FAILED: Missing -359'}\"\n",
      "Unsuccessful transaction: b\"{'to': '3', 'from': '1', 'msg': 'This is a transaction #72 on channel 98', 'amount': '196', 'channel': '>>transactions:98', 'id': '1616675582791-0', 'status': 'FAILED: Missing -73'}\"\n",
      "Unsuccessful transaction: b\"{'to': '3', 'from': '3', 'msg': 'This is a transaction #73 on channel 98', 'amount': '368', 'channel': '>>transactions:98', 'id': '1616675582791-1', 'status': 'FAILED: Missing -209'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '3', 'msg': 'This is a transaction #74 on channel 98', 'amount': '361', 'channel': '>>transactions:98', 'id': '1616675582792-0', 'status': 'FAILED: Missing -202'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '1', 'msg': 'This is a transaction #77 on channel 98', 'amount': '374', 'channel': '>>transactions:98', 'id': '1616675582802-0', 'status': 'FAILED: Missing -342'}\"\n",
      "Unsuccessful transaction: b\"{'to': '0', 'from': '1', 'msg': 'This is a transaction #79 on channel 98', 'amount': '420', 'channel': '>>transactions:98', 'id': '1616675582806-0', 'status': 'FAILED: Missing -388'}\"\n",
      "Unsuccessful transaction: b\"{'to': '1', 'from': '1', 'msg': 'This is a transaction #81 on channel 99', 'amount': '114', 'channel': '>>transactions:99', 'id': '1616675582825-0', 'status': 'FAILED: Missing -56'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '1', 'msg': 'This is a transaction #85 on channel 99', 'amount': '485', 'channel': '>>transactions:99', 'id': '1616675582831-0', 'status': 'FAILED: Missing -340'}\"\n",
      "Unsuccessful transaction: b\"{'to': '1', 'from': '0', 'msg': 'This is a transaction #86 on channel 99', 'amount': '150', 'channel': '>>transactions:99', 'id': '1616675582832-0', 'status': 'FAILED: Missing -72'}\"\n",
      "Unsuccessful transaction: b\"{'to': '3', 'from': '0', 'msg': 'This is a transaction #89 on channel 99', 'amount': '132', 'channel': '>>transactions:99', 'id': '1616675582835-0', 'status': 'FAILED: Missing -54'}\"\n",
      "Unsuccessful transaction: b\"{'to': '1', 'from': '2', 'msg': 'This is a transaction #90 on channel 93', 'amount': '412', 'channel': '>>transactions:93', 'id': '1616675582811-0', 'status': 'FAILED: Missing -21'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '2', 'msg': 'This is a transaction #93 on channel 93', 'amount': '466', 'channel': '>>transactions:93', 'id': '1616675582817-0', 'status': 'FAILED: Missing -92'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '1', 'msg': 'This is a transaction #97 on channel 93', 'amount': '465', 'channel': '>>transactions:93', 'id': '1616675582824-0', 'status': 'FAILED: Missing -433'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '1', 'msg': 'This is a transaction #98 on channel 93', 'amount': '242', 'channel': '>>transactions:93', 'id': '1616675582825-0', 'status': 'FAILED: Missing -210'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '0', 'msg': 'This is a transaction #91 on channel 99', 'amount': '166', 'channel': '>>transactions:99', 'id': '1616675582836-0', 'status': 'FAILED: Missing -88'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '2', 'msg': 'This is a transaction #93 on channel 99', 'amount': '489', 'channel': '>>transactions:99', 'id': '1616675582837-1', 'status': 'FAILED: Missing -125'}\"\n",
      "Unsuccessful transaction: b\"{'to': '3', 'from': '2', 'msg': 'This is a transaction #94 on channel 99', 'amount': '420', 'channel': '>>transactions:99', 'id': '1616675582837-2', 'status': 'FAILED: Missing -56'}\"\n",
      "Unsuccessful transaction: b\"{'to': '3', 'from': '0', 'msg': 'This is a transaction #96 on channel 99', 'amount': '173', 'channel': '>>transactions:99', 'id': '1616675582838-1', 'status': 'FAILED: Missing -95'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '1', 'msg': 'This is a transaction #97 on channel 99', 'amount': '356', 'channel': '>>transactions:99', 'id': '1616675582840-0', 'status': 'FAILED: Missing -238'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '2', 'msg': 'This is a transaction #99 on channel 99', 'amount': '405', 'channel': '>>transactions:99', 'id': '1616675582840-2', 'status': 'FAILED: Missing -260'}\"\n",
      "Unsuccessful transaction: b\"{'to': '0', 'from': '1', 'msg': 'This is a transaction #82 on channel 98', 'amount': '167', 'channel': '>>transactions:98', 'id': '1616675582808-0', 'status': 'FAILED: Missing -106'}\"\n",
      "Unsuccessful transaction: b\"{'to': '4', 'from': '1', 'msg': 'This is a transaction #86 on channel 98', 'amount': '335', 'channel': '>>transactions:98', 'id': '1616675582819-0', 'status': 'FAILED: Missing -150'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '4', 'msg': 'This is a transaction #91 on channel 96', 'amount': '439', 'channel': '>>transactions:96', 'id': '1616675582821-0', 'status': 'FAILED: Missing -100'}\"\n",
      "Unsuccessful transaction: b\"{'to': '2', 'from': '4', 'msg': 'This is a transaction #92 on channel 96', 'amount': '434', 'channel': '>>transactions:96', 'id': '1616675582824-0', 'status': 'FAILED: Missing -95'}\"\n"
     ]
    }
   ],
   "source": [
    "# Show errors\n",
    "for exe in single.gears.dumpexecutions():\n",
    "    batch = single.gears.getresults(exe.executionId)\n",
    "    if batch.errors: \n",
    "        print(f\"Errors: {batch.errors}\")\n",
    "        \n",
    "    if batch:\n",
    "        for remaining_transactions in batch.value:\n",
    "            print(f\"Unsuccessful transaction: {remaining_transactions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Transaction Stream Processing Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unregister all registrations\n",
    "for reg in single.gears.dumpregistrations():\n",
    "    single.gears.unregister(reg.id)\n",
    "\n",
    "# Remove all executions\n",
    "for exe in single.gears.dumpexecutions():\n",
    "    signle.gears.dro\n",
    "    single.gears.dropexecution(str(exe.executionId))\n",
    "\n",
    "# Clear all keys\n",
    "single.flushall()\n",
    "\n",
    "# Check that there are no keys\n",
    "single.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-command\"></a>\n",
    "## 4. Custom Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Demo 4 - Custom Command\")\n",
    "cluster = redgrease.RedisGears(\n",
    "    startup_nodes=[\n",
    "        {\"host\":\"localhost\", \"port\":30001},\n",
    "        {\"host\":\"localhost\", \"port\":30002},\n",
    "        {\"host\":\"localhost\", \"port\":30003},\n",
    "    ]\n",
    ")\n",
    "cluster.hgetall(\"/dataset/COCO/annotations/category/47\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.hget(\"/dataset/coco/2014/image/74827/info\", \"coco_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "dab300696de9719b5a13d46921259e062f63d9f082fc9b215a0fc3675193508b"
   }
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
