{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedGrease Demo at RedisConf 2021\n",
    "\n",
    "Quick demonstration of how to create and run Redis Gears functions, using RedGrease.\n",
    "\n",
    "## [Demos](#Demos):\n",
    "1. [The Basics](#1.-The-Basics)\n",
    "2. [Complex Query](#2.-Complex-Query)\n",
    "3. [Transaction Stream Processing](#3.-Transaction-Stream-Processing)\n",
    "4. [Custom Command](#4.-Custom-Command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preparations\n",
    "Before running the demos, make sure that the prerequisites are met and that the preparation steps have successfully been executed. \n",
    "Some preparation steps, particularly the downloads, may take quite some time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n",
    "- Python3.7\n",
    "- Pip\n",
    "- Docker\n",
    "- Jupyter\n",
    "\n",
    "Run the cell below tho validate your prerequisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell to test your environment requirements\n",
    "\n",
    "import sys\n",
    "import re\n",
    "pyver = !{sys.executable} --version  # type: ignore \n",
    "pipver = !{sys.executable} -m pip --version  # type: ignore\n",
    "dockver = !docker --version  # type: ignore\n",
    "\n",
    "if not re.match(\"Python 3.7\", pyver[0]):\n",
    "    raise SystemExit(f\"This demo only supports Python 3.7. You are running {pyver[0]}.\")\n",
    "\n",
    "if not re.match(\".*\\(python 3.7\\)\", pipver[0]):\n",
    "    raise SystemExit(\"Please install Pip for yout Python 3.7 environment.\")\n",
    "\n",
    "if not re.match(\"Docker version\", dockver[0]):\n",
    "    raise SystemExit(\"Please install Docker\")\n",
    "\n",
    "print(\"Requirements all look good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python Requirements\n",
    "\n",
    "Install the Python packages required for the demo:\n",
    "\n",
    "- `redgrease[client]` - The RedGrease client library for Redis Gears. This is what is being demonstrated.\n",
    "\n",
    "- `ipywidgets` - Jupyter notebook exetension, for displaying widgets, e.g. buttons, in this notebook.\n",
    "- `requests` - For downloading content.\n",
    "\n",
    "Run the cell below to install the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture reqs_install_output\n",
    "!{sys.executable} -m pip install redgrease[client]==0.1.33 ipywidgets requests\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Datasets\n",
    "Some of the demos requiere a portion of the [COCO Dataset](https://cocodataset.org) to be uploaded into the Redis Gears Cluster.\n",
    "The COCO Dataset (Common Objects in Context) is a fairly large set of (~247,000) images and corresponding annotations of what tey are depicting.\n",
    "\n",
    "### Example:\n",
    "<img src=\"coco_example.jpg\" > [COCO Example](coco_example.jpg)\n",
    "\n",
    "```\n",
    "a man riding a snowboard down a ski slope.\n",
    "a snowboarder sailing down a snowy hillside on a mountain.\n",
    "a man is snowboarding past blue markers on a mountain.\n",
    "a man on a snowboard in the snow.\n",
    "a man snow boarding in the snow on a slope. \n",
    "```\n",
    "\n",
    "\n",
    "For the demo we will only pre-download the annotations (json), not the images (jpeg), but it is still between 250 - 500 MB of data, depending on which portions you choose.\n",
    "\n",
    "There are two annotation packages to choose from. \n",
    "- **COCO Train/Cal 2014** - Annotations for 124,000 images (241 MB)\n",
    "- **COCO Train/Val 2017** - Annotations for 123,000 images (241 MB)\n",
    "\n",
    "Either or both may be used. \n",
    "Run the cell below and select using the buttons which dataset(s) to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is just for preparation of the demo.\n",
    "# It is NOT part of the demo itself\n",
    "#\n",
    "# Download COCO Annotations \n",
    "# Run the cell, then:\n",
    "# - Validate or modify the Download directory\n",
    "# - Click the button, or buttons for the annotations to download\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import requests\n",
    "\n",
    "coco_annotations_url = \"http://images.cocodataset.org/annotations\"\n",
    "annotations_file_pattern = \"annotations_trainval{}.zip\"\n",
    "\n",
    "layout = widgets.Layout(width=\"30%\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def get_download_path():\n",
    "    download_dir = \".\"\n",
    "    if os.name == 'nt':\n",
    "        import winreg\n",
    "        sub_key = r'SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders'\n",
    "        downloads_guid = '{374DE290-123F-4565-9164-39C4925E467B}'\n",
    "        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, sub_key) as key:\n",
    "            download_dir = winreg.QueryValueEx(key, downloads_guid)[0]\n",
    "    else:\n",
    "        download_dir = os.path.join(os.path.expanduser('~'), 'Downloads')\n",
    "\n",
    "    return os.path.join(download_dir, \"COCO\")\n",
    "\n",
    "download_location = widgets.Text(\n",
    "    value=get_download_path(),\n",
    "    placeholder=\"Download directory\",\n",
    "    description=\"Directory to download annotations to.\",\n",
    "    layout=layout,\n",
    ")\n",
    "display(download_location)\n",
    "\n",
    "def dl_state(button, downloading=None):\n",
    "    year = button.value\n",
    "    annotations_file_name = annotations_file_pattern.format(year)\n",
    "    destination = os.path.join(download_location.value, annotations_file_name)\n",
    "    is_downloaded = os.path.isfile(destination)\n",
    "    button.disabled = is_downloaded or downloading is not None\n",
    "    if downloading:\n",
    "        button.description=f\"Downloading COCO {year} annotations (241 MB): {downloading}%. Please wait!\"\n",
    "    elif is_downloaded:\n",
    "        button.description=f\"Congrats! COCO {year} annotataions is downloaded!\"\n",
    "    else:\n",
    "        button.description=f\"Download COCO {year} annotations (241 MB)\"\n",
    "    return is_downloaded, annotations_file_name, destination\n",
    "\n",
    "\n",
    "def download_button_pressed(btn):\n",
    "    downloaded, file_name, destination = dl_state(btn)\n",
    "    if downloaded:\n",
    "        return\n",
    "    if not os.path.isdir(download_location.value):\n",
    "        os.mkdir(download_location.value)\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{coco_annotations_url}/{file_name}\",\n",
    "            stream=True\n",
    "        )\n",
    "        total_length = response.headers.get('content-length')\n",
    "        with open(destination, \"wb\") as f:\n",
    "            if total_length is None: # no content length header\n",
    "                dl_state(btn, \"???\")\n",
    "                f.write(response.content)\n",
    "                return\n",
    "            total_length = int(total_length)\n",
    "            dl = 0\n",
    "            for data in response.iter_content(chunk_size=4096):\n",
    "                dl += len(data)\n",
    "                f.write(data)\n",
    "                dl_state(btn, int(100*(dl/total_length)))\n",
    "\n",
    "    except Exception:\n",
    "        try:\n",
    "            os.remove(destination)\n",
    "        except Exception:\n",
    "            pass\n",
    "    finally:\n",
    "        dl_state(btn)\n",
    "\n",
    "for year in [\"2014\", \"2017\"]:\n",
    "    download_button = widgets.Button(\n",
    "        tooltip='Start download of selected datasets into the selected download directory.',\n",
    "        layout=layout\n",
    "    )\n",
    "    download_button.value = year\n",
    "    dl_state(download_button)\n",
    "    download_button.on_click(download_button_pressed)\n",
    "    display(download_button)\n",
    "\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download and run Redis Gears Cluster Docker image\n",
    "Run the cell below to download a Redis Gears Cluster Docker image (~605 MB), if not already present, and run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_gears_cluster_image = \"redislabs/rgcluster:1.0.6\"\n",
    "redis_gears_cluster_container_name = \"demo_gears_cluster\"\n",
    "\n",
    "redis_gears_single_image = \"redislabs/redisgears:1.0.6\"\n",
    "redis_gears_single_container_name = \"demo_gears_single\"\n",
    "\n",
    "# Get the correct Redis Gears Images\n",
    "!docker pull {redis_gears_single_image}\n",
    "!docker pull {redis_gears_cluster_image}\n",
    "\n",
    "# Check if the single container is already running.\n",
    "container_info = !docker container inspect {redis_gears_single_container_name}\n",
    "if container_info[0] == \"[]\":\n",
    "    print(\"Starting Redis Gears single instance\")\n",
    "    !docker run --name {redis_gears_single_container_name} --rm -d -p 6379:6379 {redis_gears_single_image}\n",
    "\n",
    "\n",
    "# Check if the cluster container is already running.\n",
    "container_info = !docker container inspect {redis_gears_cluster_container_name}\n",
    "if container_info[0] == \"[]\":\n",
    "    print(\"Starting Redis Gears cluster instance\")\n",
    "    !docker run --name {redis_gears_cluster_container_name} --rm -d -p 30001:30001 -p 30002:30002 -p 30003:30003 {redis_gears_cluster_image}\n",
    "\n",
    "print(\"Redis Gears containers are running!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Annotation Data into Redis cluster\n",
    "By running the cell below, the COCO annotations downloaded above will be loaded into the Redis Cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import redgrease\n",
    "import zipfile\n",
    "\n",
    "annotation_archive_files = os.path.join(download_location.value, \"annotations_trainval*.zip\")\n",
    "annotation_archives = glob.glob(annotation_archive_files)\n",
    "\n",
    "if not annotation_archives:\n",
    "    print(\"no archives\")\n",
    "    raise SystemExit(\"Please download either or both COCO annotations as per instructions above.\")\n",
    "\n",
    "r = redgrease.RedisGears(host=\"localhost\", port=30001)\n",
    "\n",
    "annotation_json_pattern = re.compile(\"annotations/(\\w+)_([a-zA-Z]+)([0-9]+).json\")\n",
    "\n",
    "annotation_types = [\"instances\"]  #, \"person_keypoints\", \"captions\"]\n",
    "years = [\"2014\", \"2017\"]\n",
    "purpose = [\"val\", \"train\"]\n",
    "\n",
    "output = widgets.Output()\n",
    "progress = widgets.Text(\"\", layout=layout)\n",
    "\n",
    "def load_annotation_info(base_key, info):\n",
    "    annotation_info_key = f\"{base_key}/info\"\n",
    "    r.hset(annotation_info_key, mapping=info)\n",
    "    return annotation_info_key\n",
    "\n",
    "def load_license_info(base_key, license):\n",
    "    license_key = f\"{base_key}/license/{license['id']}\"\n",
    "    if not r.exists(license_key):\n",
    "        r.hset(license_key, mapping=license)\n",
    "    return license_key\n",
    "\n",
    "def load_image_info(base_key, image_info):\n",
    "    img_info_key = f\"{base_key}/image/{image_info['id']}/info\"\n",
    "    if not r.exists(img_info_key):\n",
    "        r.hset(img_info_key, mapping=image_info)\n",
    "    return img_info_key\n",
    "\n",
    "def load_keypoint_names(base_key, keypoints):\n",
    "    keypoints_key = f\"{base_key}/keypoints\"\n",
    "    r.lpush(keypoints_key, *keypoints)\n",
    "    return keypoints_key\n",
    "\n",
    "def load_list_of_str(base_key, sequence):\n",
    "    list_key = f\"{base_key}/skeleton\"\n",
    "    r.lpush(list_key, *map(str, sequence))\n",
    "    return list_key\n",
    "\n",
    "def load_category(base_key, category):\n",
    "    category_key = f\"{base_key}/category/{category['id']}\"\n",
    "\n",
    "    if \"keypoints\" in category:\n",
    "        category[\"keypoints\"] = load_keypoint_names(category_key, category[\"keypoints\"])\n",
    "    if \"skeleton\" in category:\n",
    "        category[\"skeleton\"] = load_list_of_str(category_key, category[\"skeleton\"])\n",
    "\n",
    "    r.hset(category_key, mapping=category)\n",
    "    return category_key\n",
    "\n",
    "def load_segmentation(base_key, segmentation):\n",
    "    segmentation_key = f\"{base_key}/segmentation\"\n",
    "    if not r.exists(segmentation_key):\n",
    "        for i, segment in enumerate(segmentation):\n",
    "            segment_key = f\"{segmentation_key}/{i}\"\n",
    "            r.lpush(segment_key, *segment)\n",
    "            r.rpush(segmentation_key, segment_key)\n",
    "    return segmentation_key\n",
    "\n",
    "def load_annotation(base_key, annotation):\n",
    "    \n",
    "    annotation_key = f\"{base_key}/image/{annotation['image_id']}/annotation/{annotation['id']}\"\n",
    "    \n",
    "    if not r.exists(annotation_key):\n",
    "        if \"segmentation\" in annotation:\n",
    "            # Replace the 'segmentation' list-of-lists, with a key with a list of keys, that in turn point to the inner lists :)\n",
    "            annotation[\"segmentation\"] = load_segmentation(annotation_key, annotation[\"segmentation\"])\n",
    "        \n",
    "        if \"bbox\" in annotation:\n",
    "            # Replace the 'bbox' with a string reepresentaton.load_segmentation\n",
    "            annotation[\"bbox\"] = str(annotation[\"bbox\"])\n",
    "\n",
    "        if \"keypoints\" in annotation:\n",
    "            annotation[\"keypoints\"] = load_list_of_str(annotation_key, annotation[\"keypoints\"])\n",
    "\n",
    "        r.hset(annotation_key, mapping=annotation)\n",
    "    return annotation_key\n",
    "\n",
    "def load_annotation_jsons_from_zip(zip_file):\n",
    "    with zipfile.ZipFile(zip_file) as archive:\n",
    "        for file_name in archive.namelist():\n",
    "            is_annotation_file = annotation_json_pattern.match(file_name)\n",
    "            if not is_annotation_file:\n",
    "                continue\n",
    "            \n",
    "            annotation_type = is_annotation_file.group(1)\n",
    "            dataset_purpose = is_annotation_file.group(2)\n",
    "            dataset_year = is_annotation_file.group(3)\n",
    "\n",
    "            if not annotation_type in annotation_types:\n",
    "                continue\n",
    "            \n",
    "            if not dataset_purpose in purpose:\n",
    "                continue\n",
    "                \n",
    "            if not dataset_year in years:\n",
    "                continue\n",
    "\n",
    "            with archive.open(file_name) as json_file:\n",
    "                contents = json.load(json_file)\n",
    "    \n",
    "            base_key = f\"/dataset/coco/{dataset_year}\"\n",
    "            info_key = f\"{base_key}/general/{annotation_type}/{dataset_purpose}\"\n",
    "                \n",
    "            # info\n",
    "            if \"info\" in contents:\n",
    "                progress.value = f\"Loading info for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                load_annotation_info(info_key, contents[\"info\"])\n",
    "\n",
    "            # licenses\n",
    "            if \"licenses\" in contents:\n",
    "                progress.value = f\"Loading licenses for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                for lic in contents[\"licenses\"]:\n",
    "                    load_license_info(info_key, lic)\n",
    "                    \n",
    "            # images\n",
    "            if \"images\" in contents:\n",
    "                progress.value = f\"Loading images for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                for image_info in contents[\"images\"]:\n",
    "                    load_image_info(base_key, image_info)\n",
    "\n",
    "            # annotations\n",
    "            if \"annotations\" in contents:\n",
    "                progress.value = f\"Loading annotations for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                for annotation in contents[\"annotations\"]:\n",
    "                    load_annotation(base_key, annotation)\n",
    "\n",
    "            # categories (for \"instances\" and \"person_keypoints\")\n",
    "            if \"categories\" in contents:\n",
    "                progress.value = f\"Loading categories for {dataset_purpose} {dataset_year} {annotation_type}\"\n",
    "                for category in contents[\"categories\"]:\n",
    "                    load_category(base_key, category)\n",
    "\n",
    "            \n",
    "display(progress)\n",
    "for archive in annotation_archives:\n",
    "    progress.value = f\"Unzipping {archive}\"\n",
    "    load_annotation_jsons_from_zip(archive)\n",
    "progress.value = \"Done!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos\n",
    "This is the actual Demo section. Everything above is just preparations.\n",
    "\n",
    "1. [The Basics](#1.-The-Basics)\n",
    "2. [Complex Query](#2.-Complex-Query)\n",
    "3. [Transaction Stream Processing](#3.-Transaction-Stream-Processing)\n",
    "4. [Custom Command](#4.-Custom-Command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demm-basics\"></a>\n",
    "## 1. The Basics\n",
    "Showcasing some of the basic features and commands of the redgrease package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiation of client / connection to Redis Gears engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redgrease\n",
    "import redgrease.utils\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "# Create connection / client for single instance Redis\n",
    "single = redgrease.RedisGears() \n",
    "\n",
    "# Create connectoin / client for Redis Cluster \n",
    "cluster = redgrease.RedisGears(\n",
    "    startup_nodes=[\n",
    "        {\"host\":\"localhost\", \"port\":30001},\n",
    "        {\"host\":\"localhost\", \"port\":30002},\n",
    "        {\"host\":\"localhost\", \"port\":30003},\n",
    "    ]\n",
    ")\n",
    "print(f\"single: {single.ping()}\")\n",
    "print(f\"cluster:\\n{cluster.ping()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redis v6 commands are accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = single.flushall()\n",
    "b = single.set(\"Foo\", 21)\n",
    "c = single.hset(\"Bar\", mapping={\"spam\":\"eggs\", \"meaning\":8})\n",
    "d = single.hincrby(\"Bar\", \"meaning\", 34)\n",
    "e = single.xadd(\"tlogs::0\", {\"msg\":\"START\", \"from\":0, \"to\":0, \"amount\":0})\n",
    "\n",
    "a, b, c, d, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gears-specific commands can be accessed through the `gears` property.\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_pystats = cluster.gears.pystats()\n",
    "\n",
    "print(f\"Cluster Redis - Python Stats:\\n{cluster_pystats}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_info = cluster.gears.infocluster()\n",
    "\n",
    "print(f\"Cluster Redis - Cluster Info:\\n{cluster_info}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_refreshed = cluster.gears.refreshcluster()\n",
    "\n",
    "print(f\"Cluster Redis - Cluster Refresh Response:\\n{cluster_refreshed}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pystats = single.gears.pystats()\n",
    "\n",
    "print(f\"Single-node Redis - Python Stats:\\n{single_pystats}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gear functions can be invoked as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> Iterate through all Redis key-value records, and return all record data.\n",
    "all_records_gear = single.gears.pyexecute(\"GearsBuilder().run()\")\n",
    "\n",
    "print(\"Single-node Redis - All-records gear: [\")\n",
    "for result in all_records_gear:\n",
    "    print(f\"  {result}\")\n",
    "print(\"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> Iterate through all Redis key-value records, and return just the key and type\n",
    "key_type_gear = single.gears.pyexecute(\n",
    "    \"GearsBuilder().map(lambda record:(record['key'], record['type'])).run()\"\n",
    ")\n",
    "\n",
    "print(\"Single-node Redis - Key-types gear: [\")\n",
    "for result in key_type_gear:\n",
    "    print(f\"  {result}\")\n",
    "print(\"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> Count the total number of keys / records\n",
    "single_record_count = single.gears.pyexecute(\"GearsBuilder().count().run()\")\n",
    "\n",
    "print(f\"Single-node Redis - Record count: {single_record_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GearFunction objects\n",
    "RedGrease allows for cunstruction of GearFuntion objects instread of function strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Programatic / dynamic definition of Gears functions\n",
    "record_count = redgrease.KeysOnlyReader().count().run()\n",
    "\n",
    "cluster_record_count = cluster.gears.pyexecute(record_count)\n",
    "\n",
    "print(f\"Cluster Redis - Total records: {cluster_record_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial RedGrease GearFunction objects can be composed and reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>\n",
    "images = (\n",
    "    redgrease.KeysReader(\"/dataset/coco/*/image/*/info\")\n",
    "    .map(lambda record: record['value'])\n",
    ")\n",
    "\n",
    "image_count = images.count()\n",
    "\n",
    "square_images = images.filter(lambda img: img['height'] == img['width'])\n",
    "\n",
    "some_image_urls = (\n",
    "    square_images\n",
    "    .collect()\n",
    "    .limit(4)\n",
    "    .map(lambda record: record['coco_url'])\n",
    ")\n",
    "\n",
    "type(images), type(image_count), type(square_images), type(some_image_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can dynamically create parameterized partial RedGrease GearFunctions in normal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> Normal functions can create paramenterized Gear Functions\n",
    "def instance_annotations(year=\"*\"):\n",
    "    return (\n",
    "        redgrease.KeysReader(f\"/dataset/coco/{year}/image/*/annotation/*\")\n",
    "        .filter(lambda record: record['type'] == \"hash\")\n",
    "        .map(lambda record: record[\"value\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gears Functions can be exectuted in a number of different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The \"textbook\" way\n",
    "img_cnt = cluster.gears.pyexecute(image_count.run())\n",
    "\n",
    "print(f\"Total number of images: {img_cnt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### As a partial function, i.e. without a closing 'run' or 'register' (Run is inferred)\n",
    "annotation_cnt = cluster.gears.pyexecute(instance_annotations().count())\n",
    "\n",
    "print(f\"Total number of annotations: {annotation_cnt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> Directly from a closed GearFunction, using the `on`-method\n",
    "avg_square_size = square_images.map(lambda sq: sq['width']).avg().run()\n",
    "\n",
    "print(f\"Look, it aint no PartialGearFunction no more. it is a {type(avg_square_size)}\")\n",
    "avg_square_size.on(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> Directly in the closing `run` or `register` operation, using the `on` argument\n",
    "img_urls = some_image_urls.run(on=cluster)\n",
    "\n",
    "print(f\"Some square images\")\n",
    "for img_url in img_urls:\n",
    "    display(Image(url=img_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-query\"></a>\n",
    "## 2. Complex Query \n",
    "\n",
    "Let's construct a query GearFunction that can take a number of annotation category names and for each an optional min and max count, \n",
    "and then finds images that fit those constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, notice how annotations are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = cluster.hgetall(\"/dataset/coco/2017/image/22222/annotation/2027787\")\n",
    "a2 = cluster.hgetall(\"/dataset/coco/2017/image/22222/annotation/1727529\")\n",
    "a1, a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create some lookup tables for the annotation categories and their IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> Merging dicttionaries\n",
    "def dict_merge(d1, d2):\n",
    "    return {**d1, **d2}\n",
    "\n",
    "# Lookup from category name to category id\n",
    "category_id_lookup = (\n",
    "    redgrease.KeysReader(\"/dataset/*/category/*\")\n",
    "    .filter(lambda record: record['type'] == 'hash')\n",
    "    .map(lambda record: {record['value']['name']:record['value']['id']})\n",
    "    .aggregate({},dict_merge, dict_merge)\n",
    "    .run(on=cluster)\n",
    ")\n",
    "\n",
    "category_name_lookup = {cat_id:cat_name for cat_name, cat_id in category_id_lookup.items() }\n",
    "\n",
    "print(f\"Number of categories: {len(category_id_lookup)}\")\n",
    "print(f\"Errors: {category_id_lookup.errors}\")\n",
    "print()\n",
    "print(f\"Lookup id by name:\\n{category_id_lookup}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the number of annotations of each category per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for each annotation we add one the accumulator for the image, under the category of the annotation\n",
    "def accumulate_categories(image_id, accumulator, annotation):\n",
    "    if 'category_id' in annotation:\n",
    "        annotation_category_id = annotation['category_id']\n",
    "        accumulator[annotation_category_id] = accumulator.get(annotation_category_id, 0) + 1\n",
    "        return accumulator\n",
    "\n",
    "    \n",
    "# add the previousls accumlated counts from eace shard to a global ccumulator for the image\n",
    "def accumulate_category_counts(image_id, accumulator, category_count):\n",
    "    for category, count in category_count.items():\n",
    "        accumulator[category] = accumulator.get(category, 0) + count\n",
    "    return accumulator\n",
    "\n",
    "\n",
    "# Just renaming fields so it's clearer what they contain\n",
    "def format_img_stats(img_stats):\n",
    "    return {\n",
    "        'image_id': img_stats['key'],\n",
    "        'instances': img_stats['value']\n",
    "    }\n",
    "\n",
    "\n",
    "# GearFunction that counts the number of annotations of each category in each image\n",
    "category_count_by_image = instance_annotations(2017).aggregateby(\n",
    "    extractor = lambda annotation : annotation.get('image_id', -1),  # Group the annotatioms by image_id\n",
    "    zero = {},  # For each group we use a dict to accumulate the counts of each category of annotaion\n",
    "    seqOp = accumulate_categories,  # Accumulate/reduce the category counts locally on each shard\n",
    "    combOp = accumulate_category_counts  # Accumulate/reduce the local results globally\n",
    ").map(format_img_stats)\n",
    "\n",
    "\n",
    "\n",
    "# Run the GearFunction, but limit to 10 results per shard (for sanity)\n",
    "cats_by_img = category_count_by_image.limit(10).run(on=cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>\n",
    "print(f\"Number of results: {len(cats_by_img)}\")\n",
    "print(f\"Errors: {cats_by_img.errors}\")\n",
    "print()\n",
    "for img in cats_by_img:\n",
    "    inst = { category_name_lookup.get(cid, cid):cnt for cid, cnt in img['instances'].items() }\n",
    "    print(f\"Image #{img['image_id']} instances: {inst}\")\n",
    "print(\"...\")\n",
    "print(\"and so on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Querying \n",
    "\n",
    "def contstrain(constraints):\n",
    "    # return a predicate for instance counts where the count of a set of categories\n",
    "    # Constraints is a dict from category name to a tuple of (min_count, max_count)\n",
    "    \n",
    "    id_constraints = { category_id_lookup[cat_name]:x for cat_name, x in constraints.items()}\n",
    "    \n",
    "    def predicate(record):\n",
    "        instances = record['instances']\n",
    "        \n",
    "        # iterate through each of the constraints, to check if any fails\n",
    "        \n",
    "        for cat_id, constraint in id_constraints.items():\n",
    "            min_count, max_count = constraint\n",
    "            \n",
    "            if cat_id not in instances:\n",
    "                if min_count is not ... and min_count > 0:\n",
    "                    return False\n",
    "                continue\n",
    "            \n",
    "            if min_count is not ... and instances[cat_id] < min_count:\n",
    "                return False\n",
    "            \n",
    "            if max_count is not ... and instances[cat_id] > max_count:\n",
    "                return False\n",
    "            \n",
    "        return True\n",
    "\n",
    "    return predicate\n",
    "\n",
    "\n",
    "# Our query params is a dict of category name to a min and max count tuple (... meaninig any)\n",
    "query_params = {\n",
    "    'truck': (1, 2),\n",
    "    'banana': (5, ...),\n",
    "    'person': (1, 1),\n",
    "    'orange': (..., 0),\n",
    "}\n",
    "\n",
    "\n",
    "query = category_count_by_image.filter(contstrain(query_params))\n",
    "\n",
    "query_result = query.limit(30).run(on=cluster)\n",
    "\n",
    "query_result, query_result.errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> Show the resulting images\n",
    "image_ids = [result['image_id'] for result in query_result]\n",
    "\n",
    "image_urls = (\n",
    "    redgrease.KeysReader(\"/dataset/coco/2017/image/*/info\")\n",
    "    .map(lambda record: record['value'])\n",
    "    .filter(lambda img: img['id'] in image_ids)\n",
    "    .map(lambda img: img[\"coco_url\"])\n",
    "    .run(on=cluster)\n",
    ")\n",
    "\n",
    "for image_url in image_urls:\n",
    "    display(Image(url=image_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-stream\"></a>\n",
    "## 3. Transaction Stream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "\n",
    "user_count = 5\n",
    "min_start_balance = 100\n",
    "max_start_balance = 1000\n",
    "\n",
    "\n",
    "# Create some 'user' accounts with some existing balance\n",
    "for user_id in range(user_count):\n",
    "    start_balance = random.randint(min_start_balance, max_start_balance)\n",
    "    single.hset(\n",
    "        f\"/user/{user_id}\",\n",
    "        mapping={\n",
    "            \"id\": user_id, \n",
    "            \"balance\": start_balance,\n",
    "            \"start_balance\": start_balance,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "\n",
    "# Helper function for sending transaction requests.\n",
    "def attempt_random_transaction(channel, max_amount=100, message=\"This is a random transaction\",):\n",
    "    single.xadd(\n",
    "        f\"transactions:{channel}\", \n",
    "        {\n",
    "            \"msg\": message, \n",
    "            \"from\": random.randint(0, user_count-1), \n",
    "            \"to\": random.randint(0, user_count-1), \n",
    "            \"amount\": random.randint(1, max_amount),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Print a summary balance sheet for all users \n",
    "def balance_sheet():\n",
    "    sum_balance = 0\n",
    "    for user_id in range(user_count):\n",
    "        current_balance, start_balance = map(\n",
    "            int, \n",
    "            single.hmget(f\"/user/{user_id}\", \"balance\", \"start_balance\")\n",
    "        )\n",
    "        print(f\"User {user_id} balance: {current_balance}  ({current_balance-start_balance})\")\n",
    "        sum_balance += current_balance\n",
    "    print(\"----------------------------\")\n",
    "    print(f\"Total balance : {sum_balance}\")\n",
    "    return sum_balance\n",
    "\n",
    "start_total_balance = balance_sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform a key-space event to a transaction\n",
    "def initialize_transaction(event):\n",
    "    transaction = event['value']\n",
    "    transaction['timestamp'] = datetime.datetime.utcnow().isoformat()\n",
    "    transaction['channel'] = event['key']\n",
    "    transaction['id'] = event['id']\n",
    "    transaction['status'] = \"pending\"\n",
    "    return transaction\n",
    "\n",
    "    \n",
    "# Handle the transaction safely\n",
    "def handle_transaction(transaction):\n",
    "    \n",
    "    # Log the transaction event to the Redis engine log\n",
    "    redgrease.log(f\"Procesing transaction {transaction['id']}: {transaction}\")\n",
    "    \n",
    "    sender = transaction['from']\n",
    "    recipient = transaction['to']\n",
    "    \n",
    "    # Perform a sequence of commands atomically\n",
    "    with redgrease.atomic():\n",
    "        \n",
    "        # Check if the 'sender' has sufficient balance\n",
    "        sender_balance = redgrease.cmd.hget(\n",
    "                f\"/user/{sender}\",\n",
    "                \"balance\"\n",
    "            )\n",
    "        amount = int(transaction.get('amount', 0))\n",
    "        \n",
    "        if not sender_balance or amount > int(sender_balance):\n",
    "            # If balance is not sufficient, the transaction is marked as failed.\n",
    "            transaction['status'] = f\"FAILED: Missing {int(sender_balance)-amount}\"\n",
    "            \n",
    "        else:                      \n",
    "            # If there is sufficient balance, \n",
    "            # remove the amount from sender and add it to the recipient\n",
    "            # and mark as successful\n",
    "            redgrease.cmd.hincrby(\n",
    "                f\"/user/{sender}\",\n",
    "                \"balance\",\n",
    "                -amount\n",
    "            )\n",
    "            redgrease.cmd.hincrby(\n",
    "                f\"/user/{recipient}\",\n",
    "                \"balance\",\n",
    "                amount\n",
    "            )\n",
    "            transaction['status'] = \"successful\"\n",
    "            \n",
    "            # If successful, add the transaction to the statement of the recipient\n",
    "            redgrease.cmd.xadd(f\"/user/{recipient}/statement\", transaction)\n",
    "        \n",
    "        # Regardless of status, add the transaction to the statement of the sender\n",
    "        redgrease.cmd.xadd(f\"/user/{sender}/statement\", transaction)\n",
    "        \n",
    "    redgrease.log(f\"Done processing transaction {transaction['id']}: {transaction['status']}\")\n",
    "    return transaction\n",
    "\n",
    "    \n",
    "# Transaction processing pipeline\n",
    "transsaction_pipe = (\n",
    "    redgrease.StreamReader()  # Listen to streams\n",
    "    .map(initialize_transaction)  # Map stream events to a 'transaction' dict, and adds default.\n",
    "    .map(handle_transaction)  # Execute the transaction\n",
    "    .register(prefix=\"transactions:*\", batch=10, duration=30) # Listen to transaction stream and use batching\n",
    ")\n",
    "\n",
    "\n",
    "# Register the processing pipeline\n",
    "transsaction_pipe.on(single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for registration in single.gears.dumpregistrations():\n",
    "    print(\n",
    "        f\"Registered Gear function {registration.id} has been \"\n",
    "        f\"triggered {registration.RegistrationData.numTriggered} times.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt_random_transaction(\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import repeat\n",
    "\n",
    "# Run a bunch of transactions in parallell\n",
    "parallell_transaction_job_count = 100\n",
    "sequential_transactions_count = 100\n",
    "max_transaction_amount = 500 \n",
    "\n",
    "\n",
    "def sequential_transactions(channel=\"foo\"):\n",
    "    def attempt_transactions():\n",
    "        for transaction_id in range(sequential_transactions_count):\n",
    "            attempt_random_transaction(\n",
    "                channel, \n",
    "                max_amount=max_transaction_amount,\n",
    "                message=f\"This is a transaction #{transaction_id} on channel {channel}\",\n",
    "            )\n",
    "    return attempt_transactions\n",
    "    \n",
    "    \n",
    "def run_in_parallell(jobs):\n",
    "    with ThreadPoolExecutor() as worker:\n",
    "        tasks = [worker.submit(job) for job in jobs]\n",
    "\n",
    "        \n",
    "run_in_parallell(\n",
    "    [sequential_transactions(nm) for nm in range(parallell_transaction_job_count)]\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_total_balance = balance_sheet()\n",
    "print(f\"Total difference: {start_total_balance - end_total_balance}\")\n",
    "print()\n",
    "for registration in single.gears.dumpregistrations():\n",
    "    print(\n",
    "        f\"Registered Gear function {registration.id} has been \"\n",
    "        f\"triggered {registration.RegistrationData.numTriggered} times.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = single.xrange(\"/user/3/statement\",\"-\", \"+\", 5)\n",
    "statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unregister all registrations\n",
    "for reg in single.gears.dumpregistrations():\n",
    "    single.gears.unregister(reg.id)\n",
    "\n",
    "# Remove all executions\n",
    "for exe in single.gears.dumpexecutions():\n",
    "    single.gears.dropexecution(str(exe.executionId))\n",
    "\n",
    "# Clear all keys\n",
    "single.flushall()\n",
    "\n",
    "# Check that there are no keys\n",
    "single.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-command\"></a>\n",
    "## 4. Custom Command\n",
    "\n",
    "A simple image cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_get(url):\n",
    "    if redgrease.cmd.exists(url):\n",
    "        return bytes(redgrease.cmd.get(url))\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return bytes()\n",
    "    \n",
    "    response_data = bytes(response.content)\n",
    "    redgrease.cmd.set(url, response_data)\n",
    "    \n",
    "    return response_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "get_image = (\n",
    "    redgrease.CommandReader()\n",
    "    .map(lambda trigger: trigger[1])\n",
    "    .map(cache_get, requirements=[\"requests\"])\n",
    "    .register(trigger=\"cache_get\", on=single, convertToStr=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "%timeit\n",
    "\n",
    "image_urls_1 = [\n",
    "    \"http://images.cocodataset.org/train2017/000000246070.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000167133.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000559366.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000156242.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000169188.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000135016.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000248334.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000445906.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000318733.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000316672.jpg\", \n",
    "]\n",
    "\n",
    "for image_url in image_urls_1:\n",
    "    \n",
    "    image_data = single.gears.trigger(\"cache_get\", image_url)\n",
    "    \n",
    "    display(Image(data=image_data.value))\n",
    "    \n",
    "for registration in single.gears.dumpregistrations():\n",
    "    print(\n",
    "        f\"Registered Gear function {registration.id} has been \"\n",
    "        f\"triggered {registration.RegistrationData.numTriggered} times.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An even shorter version\n",
    "Only the command function with a function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@redgrease.trigger(on=single, convertToStr=False, requirements=[\"requests\"])\n",
    "def cache_get(url):\n",
    "    if redgrease.cmd.exists(url):\n",
    "        return bytes(redgrease.cmd.get(url))\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return bytes()\n",
    "    \n",
    "    response_data = bytes(response.content)\n",
    "    redgrease.cmd.set(url, response_data)\n",
    "    \n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "image_urls_2 = [\n",
    "    \"http://images.cocodataset.org/train2017/000000483381.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000237137.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000017267.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000197756.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000451278.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000422878.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000193332.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000475564.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000247368.jpg\",\n",
    "    \"http://images.cocodataset.org/train2017/000000416337.jpg\",\n",
    "] \n",
    "\n",
    "for image_url in image_urls_2:\n",
    "    \n",
    "    image_data = cache_get(image_url)\n",
    "    \n",
    "    display(Image(data=image_data.value))\n",
    "    \n",
    "for registration in single.gears.dumpregistrations():\n",
    "    print(\n",
    "        f\"Registered Gear function {registration.id} has been \"\n",
    "        f\"triggered {registration.RegistrationData.numTriggered} times.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "dab300696de9719b5a13d46921259e062f63d9f082fc9b215a0fc3675193508b"
   }
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}